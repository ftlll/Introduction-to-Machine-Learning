{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs480_fall20_asst4_cnn_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xuTilI8_zBtJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuTilI8_zBtJ"
      },
      "source": [
        "# Import libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9DXXrkDkgtf"
      },
      "source": [
        "# libraries (do not import additional libraries)\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, InputLayer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_b0-QUhzjQd"
      },
      "source": [
        "#Parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ3vE7_Uzl7V"
      },
      "source": [
        "# parameters for this script\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "data_augmentation = False"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP3yf0H0yvxZ"
      },
      "source": [
        "#Load data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSrfbuj7x1FV",
        "outputId": "a5e3808b-5fef-4488-f9d7-018995ffab21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xCoHEHb0oF_"
      },
      "source": [
        "#Part1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyJ-4rEe0o8F"
      },
      "source": [
        "def cnn(x_train, y_train, x_test, y_test, data_augmentation = data_augmentation):\n",
        "  # Define a convolutional neural network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "  # Compile the model before using it\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  #print(model.summary())\n",
        "\n",
        "  # normalize the data\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  # partition training set into training and validation set\n",
        "  x_validate = x_train[40000:,:]\n",
        "  x_train = x_train[:40000,:]\n",
        "  y_validate = y_train[40000:,:]\n",
        "  y_train = y_train[:40000,:]\n",
        "\n",
        "  # create a callback that will save the best model while training\n",
        "  save_best_model = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  # train without data augmentation\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[save_best_model])\n",
        "\n",
        "  # train with data augmentation\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          callbacks=[save_best_model])\n",
        "      \n",
        "  # Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "  saved_model = load_model('best_model.h5')\n",
        "  scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  #return the train and test acc\n",
        "  cnn_train = history.history['accuracy']\n",
        "  cnn_test = history.history['val_accuracy']\n",
        "\n",
        "  return cnn_train, cnn_test, scores[1]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc3M_nyjBeJr"
      },
      "source": [
        "def dnn(x_train, y_train, x_test, y_test, hidden_layer):  \n",
        "  # Define a convolutional neural network\n",
        "  model = Sequential()\n",
        "  model.add(InputLayer(x_train.shape[1:], name=\"input\"))\n",
        "  model.add(Flatten())\n",
        "  for i in range(hidden_layer):\n",
        "    model.add(Dense(512, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax', name=\"output\"))\n",
        "\n",
        "  # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "  # Compile the model before using it\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "  # normalize the data\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  # partition training set into training and validation set\n",
        "  x_validate = x_train[40000:,:]\n",
        "  x_train = x_train[:40000,:]\n",
        "  y_validate = y_train[40000:,:]\n",
        "  y_train = y_train[:40000,:]\n",
        "\n",
        "  # create a callback that will save the best model while training\n",
        "  save_best_model = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  # train without data augmentation\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[save_best_model])\n",
        "\n",
        "  # train with data augmentation\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          callbacks=[save_best_model])\n",
        "  \n",
        "  # Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "  saved_model = load_model('best_model.h5')\n",
        "  scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  train_acc = history.history['accuracy']\n",
        "  test_acc = history.history['val_accuracy']\n",
        "\n",
        "  return train_acc, test_acc, scores[1]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr-V1XZEE7wV",
        "outputId": "87ba69b8-3b77-4c54-aad2-02927764a588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cnn_train_acc, cnn_test_acc, cnn_best = cnn(x_train, y_train, x_test, y_test)\n",
        "dnn0_train_acc, dnn0_test_acc, dnn0_best = dnn(x_train, y_train, x_test, y_test, 0)\n",
        "dnn1_train_acc, dnn1_test_acc, dnn1_best = dnn(x_train, y_train, x_test, y_test, 1)\n",
        "dnn2_train_acc, dnn2_test_acc, dnn2_best = dnn(x_train, y_train, x_test, y_test, 2)\n",
        "dnn3_train_acc, dnn3_test_acc, dnn3_best = dnn(x_train, y_train, x_test, y_test, 3)\n",
        "dnn4_train_acc, dnn4_test_acc, dnn4_best = dnn(x_train, y_train, x_test, y_test, 4)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not using data augmentation.\n",
            "Epoch 1/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.8342 - accuracy: 0.3306\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.43860, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8338 - accuracy: 0.3307 - val_loss: 1.5662 - val_accuracy: 0.4386\n",
            "Epoch 2/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.5188 - accuracy: 0.4512\n",
            "Epoch 00002: val_accuracy improved from 0.43860 to 0.51660, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5188 - accuracy: 0.4511 - val_loss: 1.3649 - val_accuracy: 0.5166\n",
            "Epoch 3/20\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.3674 - accuracy: 0.5100\n",
            "Epoch 00003: val_accuracy improved from 0.51660 to 0.54810, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3672 - accuracy: 0.5101 - val_loss: 1.2665 - val_accuracy: 0.5481\n",
            "Epoch 4/20\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.2602 - accuracy: 0.5506\n",
            "Epoch 00004: val_accuracy improved from 0.54810 to 0.58330, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2601 - accuracy: 0.5508 - val_loss: 1.1693 - val_accuracy: 0.5833\n",
            "Epoch 5/20\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.1745 - accuracy: 0.5821\n",
            "Epoch 00005: val_accuracy improved from 0.58330 to 0.61650, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1742 - accuracy: 0.5821 - val_loss: 1.0936 - val_accuracy: 0.6165\n",
            "Epoch 6/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.1141 - accuracy: 0.6075\n",
            "Epoch 00006: val_accuracy did not improve from 0.61650\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1140 - accuracy: 0.6074 - val_loss: 1.0969 - val_accuracy: 0.6158\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.0559 - accuracy: 0.6274\n",
            "Epoch 00007: val_accuracy improved from 0.61650 to 0.65190, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0559 - accuracy: 0.6274 - val_loss: 0.9929 - val_accuracy: 0.6519\n",
            "Epoch 8/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.0100 - accuracy: 0.6437\n",
            "Epoch 00008: val_accuracy improved from 0.65190 to 0.66160, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0094 - accuracy: 0.6439 - val_loss: 0.9754 - val_accuracy: 0.6616\n",
            "Epoch 9/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.9627 - accuracy: 0.6610\n",
            "Epoch 00009: val_accuracy improved from 0.66160 to 0.68320, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9618 - accuracy: 0.6614 - val_loss: 0.9069 - val_accuracy: 0.6832\n",
            "Epoch 10/20\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.9290 - accuracy: 0.6724\n",
            "Epoch 00010: val_accuracy improved from 0.68320 to 0.68890, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9289 - accuracy: 0.6724 - val_loss: 0.8957 - val_accuracy: 0.6889\n",
            "Epoch 11/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.8930 - accuracy: 0.6886\n",
            "Epoch 00011: val_accuracy did not improve from 0.68890\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8925 - accuracy: 0.6889 - val_loss: 0.9028 - val_accuracy: 0.6872\n",
            "Epoch 12/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.8683 - accuracy: 0.6980\n",
            "Epoch 00012: val_accuracy improved from 0.68890 to 0.70820, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8684 - accuracy: 0.6980 - val_loss: 0.8484 - val_accuracy: 0.7082\n",
            "Epoch 13/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.8445 - accuracy: 0.7044\n",
            "Epoch 00013: val_accuracy improved from 0.70820 to 0.71960, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8442 - accuracy: 0.7045 - val_loss: 0.8198 - val_accuracy: 0.7196\n",
            "Epoch 14/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8144 - accuracy: 0.7175\n",
            "Epoch 00014: val_accuracy did not improve from 0.71960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8142 - accuracy: 0.7176 - val_loss: 0.8073 - val_accuracy: 0.7194\n",
            "Epoch 15/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7982 - accuracy: 0.7222\n",
            "Epoch 00015: val_accuracy improved from 0.71960 to 0.72350, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7988 - accuracy: 0.7219 - val_loss: 0.8019 - val_accuracy: 0.7235\n",
            "Epoch 16/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.7815 - accuracy: 0.7302\n",
            "Epoch 00016: val_accuracy improved from 0.72350 to 0.73160, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7818 - accuracy: 0.7301 - val_loss: 0.7791 - val_accuracy: 0.7316\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.7375\n",
            "Epoch 00017: val_accuracy improved from 0.73160 to 0.73680, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7633 - accuracy: 0.7375 - val_loss: 0.7669 - val_accuracy: 0.7368\n",
            "Epoch 18/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.7530 - accuracy: 0.7391\n",
            "Epoch 00018: val_accuracy improved from 0.73680 to 0.73950, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7533 - accuracy: 0.7390 - val_loss: 0.7643 - val_accuracy: 0.7395\n",
            "Epoch 19/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.7404 - accuracy: 0.7480\n",
            "Epoch 00019: val_accuracy improved from 0.73950 to 0.74590, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7405 - accuracy: 0.7479 - val_loss: 0.7449 - val_accuracy: 0.7459\n",
            "Epoch 20/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7228 - accuracy: 0.7537\n",
            "Epoch 00020: val_accuracy did not improve from 0.74590\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7235 - accuracy: 0.7533 - val_loss: 0.7414 - val_accuracy: 0.7459\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7661 - accuracy: 0.7392\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_29 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                30730     \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/20\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.9936 - accuracy: 0.2903\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.33580, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.9928 - accuracy: 0.2905 - val_loss: 1.8923 - val_accuracy: 0.3358\n",
            "Epoch 2/20\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.8602 - accuracy: 0.3485\n",
            "Epoch 00002: val_accuracy improved from 0.33580 to 0.34780, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.8602 - accuracy: 0.3485 - val_loss: 1.8516 - val_accuracy: 0.3478\n",
            "Epoch 3/20\n",
            "1235/1250 [============================>.] - ETA: 0s - loss: 1.8225 - accuracy: 0.3664\n",
            "Epoch 00003: val_accuracy improved from 0.34780 to 0.36390, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.8220 - accuracy: 0.3667 - val_loss: 1.8370 - val_accuracy: 0.3639\n",
            "Epoch 4/20\n",
            "1229/1250 [============================>.] - ETA: 0s - loss: 1.8010 - accuracy: 0.3761\n",
            "Epoch 00004: val_accuracy improved from 0.36390 to 0.36470, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.8018 - accuracy: 0.3756 - val_loss: 1.8230 - val_accuracy: 0.3647\n",
            "Epoch 5/20\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.7856 - accuracy: 0.3809\n",
            "Epoch 00005: val_accuracy did not improve from 0.36470\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7856 - accuracy: 0.3809 - val_loss: 1.8229 - val_accuracy: 0.3608\n",
            "Epoch 6/20\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.7745 - accuracy: 0.3871\n",
            "Epoch 00006: val_accuracy improved from 0.36470 to 0.37610, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7742 - accuracy: 0.3871 - val_loss: 1.8032 - val_accuracy: 0.3761\n",
            "Epoch 7/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.7647 - accuracy: 0.3897\n",
            "Epoch 00007: val_accuracy did not improve from 0.37610\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7651 - accuracy: 0.3892 - val_loss: 1.7949 - val_accuracy: 0.3757\n",
            "Epoch 8/20\n",
            "1232/1250 [============================>.] - ETA: 0s - loss: 1.7581 - accuracy: 0.3937\n",
            "Epoch 00008: val_accuracy did not improve from 0.37610\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7576 - accuracy: 0.3939 - val_loss: 1.7901 - val_accuracy: 0.3756\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.7510 - accuracy: 0.3950\n",
            "Epoch 00009: val_accuracy improved from 0.37610 to 0.38940, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7510 - accuracy: 0.3950 - val_loss: 1.7833 - val_accuracy: 0.3894\n",
            "Epoch 10/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.7460 - accuracy: 0.3980\n",
            "Epoch 00010: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7444 - accuracy: 0.3984 - val_loss: 1.7963 - val_accuracy: 0.3783\n",
            "Epoch 11/20\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.7398 - accuracy: 0.3995\n",
            "Epoch 00011: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7397 - accuracy: 0.3995 - val_loss: 1.7836 - val_accuracy: 0.3865\n",
            "Epoch 12/20\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.7347 - accuracy: 0.4022\n",
            "Epoch 00012: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7346 - accuracy: 0.4022 - val_loss: 1.7821 - val_accuracy: 0.3832\n",
            "Epoch 13/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.7302 - accuracy: 0.4053\n",
            "Epoch 00013: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7297 - accuracy: 0.4058 - val_loss: 1.7720 - val_accuracy: 0.3885\n",
            "Epoch 14/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.7269 - accuracy: 0.4043\n",
            "Epoch 00014: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7264 - accuracy: 0.4046 - val_loss: 1.7899 - val_accuracy: 0.3858\n",
            "Epoch 15/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.7220 - accuracy: 0.4090\n",
            "Epoch 00015: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7225 - accuracy: 0.4083 - val_loss: 1.7768 - val_accuracy: 0.3850\n",
            "Epoch 16/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.7188 - accuracy: 0.4104\n",
            "Epoch 00016: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7185 - accuracy: 0.4105 - val_loss: 1.7741 - val_accuracy: 0.3860\n",
            "Epoch 17/20\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.7159 - accuracy: 0.4104\n",
            "Epoch 00017: val_accuracy did not improve from 0.38940\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7161 - accuracy: 0.4105 - val_loss: 1.7749 - val_accuracy: 0.3885\n",
            "Epoch 18/20\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.7131 - accuracy: 0.4139\n",
            "Epoch 00018: val_accuracy improved from 0.38940 to 0.39250, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7130 - accuracy: 0.4139 - val_loss: 1.7656 - val_accuracy: 0.3925\n",
            "Epoch 19/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.7102 - accuracy: 0.4135\n",
            "Epoch 00019: val_accuracy did not improve from 0.39250\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7101 - accuracy: 0.4135 - val_loss: 1.7724 - val_accuracy: 0.3886\n",
            "Epoch 20/20\n",
            "1234/1250 [============================>.] - ETA: 0s - loss: 1.7077 - accuracy: 0.4156\n",
            "Epoch 00020: val_accuracy did not improve from 0.39250\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7078 - accuracy: 0.4158 - val_loss: 1.7710 - val_accuracy: 0.3869\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.7458 - accuracy: 0.3923\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_30 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,578,506\n",
            "Trainable params: 1,578,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.9931 - accuracy: 0.2795\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.35230, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9912 - accuracy: 0.2801 - val_loss: 1.8330 - val_accuracy: 0.3523\n",
            "Epoch 2/20\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.8293 - accuracy: 0.3450\n",
            "Epoch 00002: val_accuracy improved from 0.35230 to 0.37790, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8293 - accuracy: 0.3449 - val_loss: 1.7689 - val_accuracy: 0.3779\n",
            "Epoch 3/20\n",
            "1234/1250 [============================>.] - ETA: 0s - loss: 1.7737 - accuracy: 0.3679\n",
            "Epoch 00003: val_accuracy improved from 0.37790 to 0.39370, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7734 - accuracy: 0.3682 - val_loss: 1.7087 - val_accuracy: 0.3937\n",
            "Epoch 4/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.7323 - accuracy: 0.3840\n",
            "Epoch 00004: val_accuracy improved from 0.39370 to 0.41630, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7319 - accuracy: 0.3840 - val_loss: 1.6671 - val_accuracy: 0.4163\n",
            "Epoch 5/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.7027 - accuracy: 0.3977\n",
            "Epoch 00005: val_accuracy improved from 0.41630 to 0.43050, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7033 - accuracy: 0.3976 - val_loss: 1.6462 - val_accuracy: 0.4305\n",
            "Epoch 6/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.6789 - accuracy: 0.4079\n",
            "Epoch 00006: val_accuracy improved from 0.43050 to 0.43550, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6788 - accuracy: 0.4079 - val_loss: 1.6154 - val_accuracy: 0.4355\n",
            "Epoch 7/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.6617 - accuracy: 0.4131\n",
            "Epoch 00007: val_accuracy improved from 0.43550 to 0.44480, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6616 - accuracy: 0.4130 - val_loss: 1.5969 - val_accuracy: 0.4448\n",
            "Epoch 8/20\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.6423 - accuracy: 0.4204\n",
            "Epoch 00008: val_accuracy did not improve from 0.44480\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6427 - accuracy: 0.4203 - val_loss: 1.6518 - val_accuracy: 0.4093\n",
            "Epoch 9/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.6227 - accuracy: 0.4265\n",
            "Epoch 00009: val_accuracy improved from 0.44480 to 0.45380, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6233 - accuracy: 0.4265 - val_loss: 1.5743 - val_accuracy: 0.4538\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.6075 - accuracy: 0.4340\n",
            "Epoch 00010: val_accuracy did not improve from 0.45380\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6075 - accuracy: 0.4340 - val_loss: 1.5750 - val_accuracy: 0.4489\n",
            "Epoch 11/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.5931 - accuracy: 0.4381\n",
            "Epoch 00011: val_accuracy improved from 0.45380 to 0.46320, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5935 - accuracy: 0.4378 - val_loss: 1.5642 - val_accuracy: 0.4632\n",
            "Epoch 12/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.5848 - accuracy: 0.4420\n",
            "Epoch 00012: val_accuracy did not improve from 0.46320\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5844 - accuracy: 0.4421 - val_loss: 1.5527 - val_accuracy: 0.4568\n",
            "Epoch 13/20\n",
            "1233/1250 [============================>.] - ETA: 0s - loss: 1.5668 - accuracy: 0.4496\n",
            "Epoch 00013: val_accuracy did not improve from 0.46320\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5672 - accuracy: 0.4489 - val_loss: 1.5434 - val_accuracy: 0.4583\n",
            "Epoch 14/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.5594 - accuracy: 0.4508\n",
            "Epoch 00014: val_accuracy improved from 0.46320 to 0.46750, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5595 - accuracy: 0.4509 - val_loss: 1.5290 - val_accuracy: 0.4675\n",
            "Epoch 15/20\n",
            "1238/1250 [============================>.] - ETA: 0s - loss: 1.5489 - accuracy: 0.4534\n",
            "Epoch 00015: val_accuracy did not improve from 0.46750\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5488 - accuracy: 0.4535 - val_loss: 1.5265 - val_accuracy: 0.4667\n",
            "Epoch 16/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.5446 - accuracy: 0.4555\n",
            "Epoch 00016: val_accuracy improved from 0.46750 to 0.47040, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5450 - accuracy: 0.4553 - val_loss: 1.5150 - val_accuracy: 0.4704\n",
            "Epoch 17/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.5328 - accuracy: 0.4617\n",
            "Epoch 00017: val_accuracy improved from 0.47040 to 0.47580, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5330 - accuracy: 0.4615 - val_loss: 1.5139 - val_accuracy: 0.4758\n",
            "Epoch 18/20\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.5240 - accuracy: 0.4627\n",
            "Epoch 00018: val_accuracy did not improve from 0.47580\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5241 - accuracy: 0.4628 - val_loss: 1.5049 - val_accuracy: 0.4671\n",
            "Epoch 19/20\n",
            "1233/1250 [============================>.] - ETA: 0s - loss: 1.5150 - accuracy: 0.4684\n",
            "Epoch 00019: val_accuracy improved from 0.47580 to 0.48580, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5152 - accuracy: 0.4681 - val_loss: 1.4841 - val_accuracy: 0.4858\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.5103 - accuracy: 0.4732\n",
            "Epoch 00020: val_accuracy did not improve from 0.48580\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5103 - accuracy: 0.4732 - val_loss: 1.4991 - val_accuracy: 0.4748\n",
            "  1/313 [..............................] - ETA: 0s - loss: 1.3149 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.4609 - accuracy: 0.4850\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_31 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,841,162\n",
            "Trainable params: 1,841,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 2.0859 - accuracy: 0.2329\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.32920, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0844 - accuracy: 0.2336 - val_loss: 1.8867 - val_accuracy: 0.3292\n",
            "Epoch 2/20\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.9149 - accuracy: 0.3062\n",
            "Epoch 00002: val_accuracy improved from 0.32920 to 0.36780, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9150 - accuracy: 0.3061 - val_loss: 1.7942 - val_accuracy: 0.3678\n",
            "Epoch 3/20\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.8523 - accuracy: 0.3327\n",
            "Epoch 00003: val_accuracy improved from 0.36780 to 0.38220, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.8523 - accuracy: 0.3327 - val_loss: 1.7592 - val_accuracy: 0.3822\n",
            "Epoch 4/20\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.8132 - accuracy: 0.3497\n",
            "Epoch 00004: val_accuracy improved from 0.38220 to 0.39750, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.8130 - accuracy: 0.3497 - val_loss: 1.7094 - val_accuracy: 0.3975\n",
            "Epoch 5/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.7885 - accuracy: 0.3592\n",
            "Epoch 00005: val_accuracy did not improve from 0.39750\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7883 - accuracy: 0.3592 - val_loss: 1.7087 - val_accuracy: 0.3965\n",
            "Epoch 6/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.7700 - accuracy: 0.3693\n",
            "Epoch 00006: val_accuracy improved from 0.39750 to 0.42340, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.7700 - accuracy: 0.3693 - val_loss: 1.6646 - val_accuracy: 0.4234\n",
            "Epoch 7/20\n",
            "1234/1250 [============================>.] - ETA: 0s - loss: 1.7548 - accuracy: 0.3766\n",
            "Epoch 00007: val_accuracy improved from 0.42340 to 0.42770, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7539 - accuracy: 0.3767 - val_loss: 1.6420 - val_accuracy: 0.4277\n",
            "Epoch 8/20\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.7330 - accuracy: 0.3854\n",
            "Epoch 00008: val_accuracy improved from 0.42770 to 0.43150, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7330 - accuracy: 0.3853 - val_loss: 1.6415 - val_accuracy: 0.4315\n",
            "Epoch 9/20\n",
            "1233/1250 [============================>.] - ETA: 0s - loss: 1.7251 - accuracy: 0.3874\n",
            "Epoch 00009: val_accuracy did not improve from 0.43150\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.7243 - accuracy: 0.3874 - val_loss: 1.6271 - val_accuracy: 0.4290\n",
            "Epoch 10/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.7165 - accuracy: 0.3896\n",
            "Epoch 00010: val_accuracy improved from 0.43150 to 0.43360, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7164 - accuracy: 0.3897 - val_loss: 1.6280 - val_accuracy: 0.4336\n",
            "Epoch 11/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.6952 - accuracy: 0.3989\n",
            "Epoch 00011: val_accuracy did not improve from 0.43360\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6955 - accuracy: 0.3988 - val_loss: 1.6355 - val_accuracy: 0.4212\n",
            "Epoch 12/20\n",
            "1238/1250 [============================>.] - ETA: 0s - loss: 1.6895 - accuracy: 0.3996\n",
            "Epoch 00012: val_accuracy improved from 0.43360 to 0.44490, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6896 - accuracy: 0.3993 - val_loss: 1.5861 - val_accuracy: 0.4449\n",
            "Epoch 13/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.6853 - accuracy: 0.4031\n",
            "Epoch 00013: val_accuracy improved from 0.44490 to 0.44750, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6852 - accuracy: 0.4031 - val_loss: 1.5829 - val_accuracy: 0.4475\n",
            "Epoch 14/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.6757 - accuracy: 0.4053\n",
            "Epoch 00014: val_accuracy improved from 0.44750 to 0.45170, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6754 - accuracy: 0.4054 - val_loss: 1.5703 - val_accuracy: 0.4517\n",
            "Epoch 15/20\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.6647 - accuracy: 0.4109\n",
            "Epoch 00015: val_accuracy did not improve from 0.45170\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6646 - accuracy: 0.4109 - val_loss: 1.5726 - val_accuracy: 0.4469\n",
            "Epoch 16/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.6600 - accuracy: 0.4118\n",
            "Epoch 00016: val_accuracy improved from 0.45170 to 0.45580, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6598 - accuracy: 0.4119 - val_loss: 1.5511 - val_accuracy: 0.4558\n",
            "Epoch 17/20\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.6498 - accuracy: 0.4154\n",
            "Epoch 00017: val_accuracy did not improve from 0.45580\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6496 - accuracy: 0.4153 - val_loss: 1.5695 - val_accuracy: 0.4517\n",
            "Epoch 18/20\n",
            "1234/1250 [============================>.] - ETA: 0s - loss: 1.6459 - accuracy: 0.4180\n",
            "Epoch 00018: val_accuracy improved from 0.45580 to 0.45640, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6461 - accuracy: 0.4177 - val_loss: 1.5704 - val_accuracy: 0.4564\n",
            "Epoch 19/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.6439 - accuracy: 0.4152\n",
            "Epoch 00019: val_accuracy improved from 0.45640 to 0.46370, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6436 - accuracy: 0.4155 - val_loss: 1.5444 - val_accuracy: 0.4637\n",
            "Epoch 20/20\n",
            "1235/1250 [============================>.] - ETA: 0s - loss: 1.6339 - accuracy: 0.4209\n",
            "Epoch 00020: val_accuracy did not improve from 0.46370\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6331 - accuracy: 0.4211 - val_loss: 1.5408 - val_accuracy: 0.4618\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5231 - accuracy: 0.4637\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_32 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,103,818\n",
            "Trainable params: 2,103,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 2.1715 - accuracy: 0.1836\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.28950, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.1707 - accuracy: 0.1840 - val_loss: 1.9473 - val_accuracy: 0.2895\n",
            "Epoch 2/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.9824 - accuracy: 0.2653\n",
            "Epoch 00002: val_accuracy improved from 0.28950 to 0.34780, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9824 - accuracy: 0.2652 - val_loss: 1.8569 - val_accuracy: 0.3478\n",
            "Epoch 3/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.9180 - accuracy: 0.3028\n",
            "Epoch 00003: val_accuracy improved from 0.34780 to 0.35900, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9183 - accuracy: 0.3027 - val_loss: 1.8160 - val_accuracy: 0.3590\n",
            "Epoch 4/20\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.8811 - accuracy: 0.3203\n",
            "Epoch 00004: val_accuracy improved from 0.35900 to 0.37680, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8807 - accuracy: 0.3206 - val_loss: 1.7568 - val_accuracy: 0.3768\n",
            "Epoch 5/20\n",
            "1238/1250 [============================>.] - ETA: 0s - loss: 1.8512 - accuracy: 0.3350\n",
            "Epoch 00005: val_accuracy improved from 0.37680 to 0.37940, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8505 - accuracy: 0.3352 - val_loss: 1.7484 - val_accuracy: 0.3794\n",
            "Epoch 6/20\n",
            "1238/1250 [============================>.] - ETA: 0s - loss: 1.8281 - accuracy: 0.3403\n",
            "Epoch 00006: val_accuracy improved from 0.37940 to 0.38340, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8277 - accuracy: 0.3410 - val_loss: 1.7392 - val_accuracy: 0.3834\n",
            "Epoch 7/20\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.8082 - accuracy: 0.3468\n",
            "Epoch 00007: val_accuracy improved from 0.38340 to 0.41170, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8079 - accuracy: 0.3469 - val_loss: 1.7062 - val_accuracy: 0.4117\n",
            "Epoch 8/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.7913 - accuracy: 0.3543\n",
            "Epoch 00008: val_accuracy did not improve from 0.41170\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7913 - accuracy: 0.3542 - val_loss: 1.7079 - val_accuracy: 0.3946\n",
            "Epoch 9/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.7747 - accuracy: 0.3624\n",
            "Epoch 00009: val_accuracy did not improve from 0.41170\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7750 - accuracy: 0.3623 - val_loss: 1.7272 - val_accuracy: 0.3946\n",
            "Epoch 10/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.7684 - accuracy: 0.3674\n",
            "Epoch 00010: val_accuracy improved from 0.41170 to 0.41960, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7679 - accuracy: 0.3675 - val_loss: 1.6883 - val_accuracy: 0.4196\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.7484 - accuracy: 0.3716\n",
            "Epoch 00011: val_accuracy did not improve from 0.41960\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7484 - accuracy: 0.3716 - val_loss: 1.6813 - val_accuracy: 0.4148\n",
            "Epoch 12/20\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.7394 - accuracy: 0.3770\n",
            "Epoch 00012: val_accuracy improved from 0.41960 to 0.42020, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7387 - accuracy: 0.3771 - val_loss: 1.6768 - val_accuracy: 0.4202\n",
            "Epoch 13/20\n",
            "1238/1250 [============================>.] - ETA: 0s - loss: 1.7365 - accuracy: 0.3785\n",
            "Epoch 00013: val_accuracy improved from 0.42020 to 0.42720, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7372 - accuracy: 0.3784 - val_loss: 1.6909 - val_accuracy: 0.4272\n",
            "Epoch 14/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.7303 - accuracy: 0.3834\n",
            "Epoch 00014: val_accuracy did not improve from 0.42720\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7304 - accuracy: 0.3835 - val_loss: 1.6977 - val_accuracy: 0.4225\n",
            "Epoch 15/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.7255 - accuracy: 0.3849\n",
            "Epoch 00015: val_accuracy did not improve from 0.42720\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7253 - accuracy: 0.3852 - val_loss: 1.6844 - val_accuracy: 0.4251\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.7186 - accuracy: 0.3853\n",
            "Epoch 00016: val_accuracy did not improve from 0.42720\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7186 - accuracy: 0.3853 - val_loss: 1.7494 - val_accuracy: 0.4072\n",
            "Epoch 17/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.7136 - accuracy: 0.3888\n",
            "Epoch 00017: val_accuracy did not improve from 0.42720\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7134 - accuracy: 0.3889 - val_loss: 1.6864 - val_accuracy: 0.4263\n",
            "Epoch 18/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.7058 - accuracy: 0.3932\n",
            "Epoch 00018: val_accuracy did not improve from 0.42720\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7055 - accuracy: 0.3932 - val_loss: 1.6780 - val_accuracy: 0.4212\n",
            "Epoch 19/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.7048 - accuracy: 0.3907\n",
            "Epoch 00019: val_accuracy improved from 0.42720 to 0.43340, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7057 - accuracy: 0.3903 - val_loss: 1.6823 - val_accuracy: 0.4334\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.6966 - accuracy: 0.3965\n",
            "Epoch 00020: val_accuracy did not improve from 0.43340\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6966 - accuracy: 0.3965 - val_loss: 1.6998 - val_accuracy: 0.4291\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6661 - accuracy: 0.4340\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_33 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_76 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_77 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,366,474\n",
            "Trainable params: 2,366,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/20\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 2.2219 - accuracy: 0.1514\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.22400, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.2212 - accuracy: 0.1516 - val_loss: 2.0589 - val_accuracy: 0.2240\n",
            "Epoch 2/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 2.0494 - accuracy: 0.2214\n",
            "Epoch 00002: val_accuracy improved from 0.22400 to 0.29880, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0485 - accuracy: 0.2219 - val_loss: 1.9234 - val_accuracy: 0.2988\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.9730 - accuracy: 0.2675\n",
            "Epoch 00003: val_accuracy improved from 0.29880 to 0.33970, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9730 - accuracy: 0.2675 - val_loss: 1.8651 - val_accuracy: 0.3397\n",
            "Epoch 4/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.9359 - accuracy: 0.2870\n",
            "Epoch 00004: val_accuracy did not improve from 0.33970\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9361 - accuracy: 0.2870 - val_loss: 1.8610 - val_accuracy: 0.3397\n",
            "Epoch 5/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.9100 - accuracy: 0.3012\n",
            "Epoch 00005: val_accuracy improved from 0.33970 to 0.35040, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9099 - accuracy: 0.3011 - val_loss: 1.8301 - val_accuracy: 0.3504\n",
            "Epoch 6/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.8848 - accuracy: 0.3113\n",
            "Epoch 00006: val_accuracy improved from 0.35040 to 0.35900, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8847 - accuracy: 0.3114 - val_loss: 1.8452 - val_accuracy: 0.3590\n",
            "Epoch 7/20\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.8715 - accuracy: 0.3150\n",
            "Epoch 00007: val_accuracy improved from 0.35900 to 0.36500, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8715 - accuracy: 0.3152 - val_loss: 1.8076 - val_accuracy: 0.3650\n",
            "Epoch 8/20\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.8563 - accuracy: 0.3246\n",
            "Epoch 00008: val_accuracy improved from 0.36500 to 0.37210, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8563 - accuracy: 0.3247 - val_loss: 1.7982 - val_accuracy: 0.3721\n",
            "Epoch 9/20\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.8457 - accuracy: 0.3268\n",
            "Epoch 00009: val_accuracy did not improve from 0.37210\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8453 - accuracy: 0.3269 - val_loss: 1.8233 - val_accuracy: 0.3600\n",
            "Epoch 10/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.8325 - accuracy: 0.3365\n",
            "Epoch 00010: val_accuracy did not improve from 0.37210\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8332 - accuracy: 0.3361 - val_loss: 1.8497 - val_accuracy: 0.3673\n",
            "Epoch 11/20\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.8245 - accuracy: 0.3397\n",
            "Epoch 00011: val_accuracy improved from 0.37210 to 0.38000, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8244 - accuracy: 0.3396 - val_loss: 1.8121 - val_accuracy: 0.3800\n",
            "Epoch 12/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.8215 - accuracy: 0.3445\n",
            "Epoch 00012: val_accuracy did not improve from 0.38000\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8208 - accuracy: 0.3446 - val_loss: 1.8293 - val_accuracy: 0.3716\n",
            "Epoch 13/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.8079 - accuracy: 0.3509\n",
            "Epoch 00013: val_accuracy did not improve from 0.38000\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8080 - accuracy: 0.3508 - val_loss: 1.8757 - val_accuracy: 0.3450\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.8033 - accuracy: 0.3498\n",
            "Epoch 00014: val_accuracy did not improve from 0.38000\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8033 - accuracy: 0.3498 - val_loss: 1.8590 - val_accuracy: 0.3706\n",
            "Epoch 15/20\n",
            "1237/1250 [============================>.] - ETA: 0s - loss: 1.7963 - accuracy: 0.3528\n",
            "Epoch 00015: val_accuracy did not improve from 0.38000\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7970 - accuracy: 0.3526 - val_loss: 1.8583 - val_accuracy: 0.3500\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.7915 - accuracy: 0.3586\n",
            "Epoch 00016: val_accuracy improved from 0.38000 to 0.38790, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7915 - accuracy: 0.3586 - val_loss: 1.8561 - val_accuracy: 0.3879\n",
            "Epoch 17/20\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.7844 - accuracy: 0.3580\n",
            "Epoch 00017: val_accuracy did not improve from 0.38790\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7845 - accuracy: 0.3580 - val_loss: 1.8692 - val_accuracy: 0.3732\n",
            "Epoch 18/20\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.7857 - accuracy: 0.3611\n",
            "Epoch 00018: val_accuracy did not improve from 0.38790\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7857 - accuracy: 0.3612 - val_loss: 1.8624 - val_accuracy: 0.3743\n",
            "Epoch 19/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.7828 - accuracy: 0.3635\n",
            "Epoch 00019: val_accuracy did not improve from 0.38790\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7832 - accuracy: 0.3634 - val_loss: 1.8748 - val_accuracy: 0.3693\n",
            "Epoch 20/20\n",
            "1236/1250 [============================>.] - ETA: 0s - loss: 1.7815 - accuracy: 0.3647\n",
            "Epoch 00020: val_accuracy improved from 0.38790 to 0.39140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7822 - accuracy: 0.3645 - val_loss: 1.8490 - val_accuracy: 0.3914\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.8319 - accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP75n9vtN7s5",
        "outputId": "7fae3853-586b-4417-c1ac-45b72f5ff4c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "plt.plot(cnn_train_acc )\n",
        "plt.plot(dnn0_train_acc )\n",
        "plt.plot(dnn1_train_acc )\n",
        "plt.plot(dnn2_train_acc)\n",
        "plt.plot(dnn3_train_acc )\n",
        "plt.plot(dnn4_train_acc )\n",
        "\n",
        "plt.title('Train Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['CNN', 'DNN 0 layer', 'DNN 1 layer', 'DNN 2 layer', 'DNN 3 layer', 'DNN 4 layer'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(cnn_test_acc )\n",
        "plt.plot(dnn0_test_acc )\n",
        "plt.plot(dnn1_test_acc )\n",
        "plt.plot(dnn2_test_acc)\n",
        "plt.plot(dnn3_test_acc )\n",
        "plt.plot(dnn4_test_acc )\n",
        "\n",
        "plt.title('Validation Accuracy ')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['CNN', 'DNN 0 layer', 'DNN 1 layer', 'DNN 2 layer', 'DNN 3 layer', 'DNN 4 layer'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "print('best validation accuracy of CNN:', cnn_best)\n",
        "print('best validation accuracy of DNN 0 hidden layer:', dnn0_best)\n",
        "print('best validation accuracy of DNN 1 hidden layer:', dnn1_best)\n",
        "print('best validation accuracy of DNN 2 hidden layer:', dnn2_best)\n",
        "print('best validation accuracy of DNN 3 hidden layer:', dnn3_best)\n",
        "print('best validation accuracy of DNN 4 hidden layer:', dnn4_best)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best validation accuracy of CNN: 0.7391999959945679\n",
            "best validation accuracy of DNN 0 hidden layer: 0.392300009727478\n",
            "best validation accuracy of DNN 1 hidden layer: 0.48500001430511475\n",
            "best validation accuracy of DNN 2 hidden layer: 0.46369999647140503\n",
            "best validation accuracy of DNN 3 hidden layer: 0.4339999854564667\n",
            "best validation accuracy of DNN 4 hidden layer: 0.4000000059604645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsrNtCoul_lI"
      },
      "source": [
        "For part1, CNN performs much better than all DNN and DNN with only 1 hidden layer performs the best among all DNN. \\\\\n",
        "CNN performs so good because it uses small patches to calculate the weights and do linearly combination for each pixel of 2D data, which makes the performance of CNN much better than DNN. \\\\\n",
        "For DNN with different number of hidden layers, DNN without hidden layer is suitable for linearly separable data. Apprantly, it does not perform well for the given data. \\\\\n",
        "With more hidden layer, the performance goes lower. I think the reason is that with more layer, it is going to find complex hypothesis and  we are taking the risk to be overfit the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA1vT_OrzJdY"
      },
      "source": [
        "#Part 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlU-1cCBDcUk"
      },
      "source": [
        "def sigmoid_cnn(x_train, y_train, x_test, y_test, data_augmentation=data_augmentation):\n",
        "  # Define a convolutional neural network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "  # Compile the model before using it\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  #print(model.summary())\n",
        "\n",
        "  # normalize the data\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  # partition training set into training and validation set\n",
        "  x_validate = x_train[40000:,:]\n",
        "  x_train = x_train[:40000,:]\n",
        "  y_validate = y_train[40000:,:]\n",
        "  y_train = y_train[:40000,:]\n",
        "\n",
        "  # create a callback that will save the best model while training\n",
        "  save_best_model = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  # train without data augmentation\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[save_best_model])\n",
        "\n",
        "  # train with data augmentation\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          callbacks=[save_best_model])\n",
        "  # Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "  saved_model = load_model('best_model.h5')\n",
        "  scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  cnn_train = history.history['accuracy']\n",
        "  cnn_test = history.history['val_accuracy']\n",
        "  return cnn_train, cnn_test, scores[1]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtK6pzULVyGc",
        "outputId": "9f8a7aef-0416-4819-bf19-a5fc20eae40e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sigmoid_train_acc, sigmoid_test_acc, sigmoid_best = sigmoid_cnn(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not using data augmentation.\n",
            "Epoch 1/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 2.3330 - accuracy: 0.1000\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09800, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3328 - accuracy: 0.1002 - val_loss: 2.3113 - val_accuracy: 0.0980\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 2.3074 - accuracy: 0.1002\n",
            "Epoch 00002: val_accuracy improved from 0.09800 to 0.10140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3074 - accuracy: 0.1002 - val_loss: 2.3029 - val_accuracy: 0.1014\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 2.3052 - accuracy: 0.1000\n",
            "Epoch 00003: val_accuracy improved from 0.10140 to 0.10250, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3052 - accuracy: 0.1000 - val_loss: 2.3031 - val_accuracy: 0.1025\n",
            "Epoch 4/20\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 2.3046 - accuracy: 0.1026\n",
            "Epoch 00004: val_accuracy did not improve from 0.10250\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3046 - accuracy: 0.1026 - val_loss: 2.3029 - val_accuracy: 0.1016\n",
            "Epoch 5/20\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 2.3046 - accuracy: 0.0965\n",
            "Epoch 00005: val_accuracy did not improve from 0.10250\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3046 - accuracy: 0.0965 - val_loss: 2.3031 - val_accuracy: 0.0977\n",
            "Epoch 6/20\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 2.3043 - accuracy: 0.1001\n",
            "Epoch 00006: val_accuracy did not improve from 0.10250\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3043 - accuracy: 0.1000 - val_loss: 2.3032 - val_accuracy: 0.0980\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 2.3038 - accuracy: 0.1030\n",
            "Epoch 00007: val_accuracy improved from 0.10250 to 0.10520, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3038 - accuracy: 0.1030 - val_loss: 2.3011 - val_accuracy: 0.1052\n",
            "Epoch 8/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 2.1886 - accuracy: 0.1799\n",
            "Epoch 00008: val_accuracy improved from 0.10520 to 0.25550, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.1883 - accuracy: 0.1802 - val_loss: 2.0514 - val_accuracy: 0.2555\n",
            "Epoch 9/20\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 2.0245 - accuracy: 0.2656\n",
            "Epoch 00009: val_accuracy improved from 0.25550 to 0.30490, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.0246 - accuracy: 0.2657 - val_loss: 1.9359 - val_accuracy: 0.3049\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.9389 - accuracy: 0.3039\n",
            "Epoch 00010: val_accuracy improved from 0.30490 to 0.33500, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.9389 - accuracy: 0.3039 - val_loss: 1.8673 - val_accuracy: 0.3350\n",
            "Epoch 11/20\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.8797 - accuracy: 0.3255\n",
            "Epoch 00011: val_accuracy improved from 0.33500 to 0.34430, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8798 - accuracy: 0.3255 - val_loss: 1.8249 - val_accuracy: 0.3443\n",
            "Epoch 12/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.8411 - accuracy: 0.3363\n",
            "Epoch 00012: val_accuracy improved from 0.34430 to 0.35950, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8405 - accuracy: 0.3365 - val_loss: 1.7858 - val_accuracy: 0.3595\n",
            "Epoch 13/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.8144 - accuracy: 0.3479\n",
            "Epoch 00013: val_accuracy improved from 0.35950 to 0.36350, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8140 - accuracy: 0.3480 - val_loss: 1.7599 - val_accuracy: 0.3635\n",
            "Epoch 14/20\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.7888 - accuracy: 0.3552\n",
            "Epoch 00014: val_accuracy improved from 0.36350 to 0.37690, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.7884 - accuracy: 0.3553 - val_loss: 1.7377 - val_accuracy: 0.3769\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.7674 - accuracy: 0.3652\n",
            "Epoch 00015: val_accuracy improved from 0.37690 to 0.38290, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.7674 - accuracy: 0.3652 - val_loss: 1.7192 - val_accuracy: 0.3829\n",
            "Epoch 16/20\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.7456 - accuracy: 0.3764\n",
            "Epoch 00016: val_accuracy improved from 0.38290 to 0.39150, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.7455 - accuracy: 0.3765 - val_loss: 1.6973 - val_accuracy: 0.3915\n",
            "Epoch 17/20\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.7246 - accuracy: 0.3808\n",
            "Epoch 00017: val_accuracy did not improve from 0.39150\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.7251 - accuracy: 0.3808 - val_loss: 1.6866 - val_accuracy: 0.3902\n",
            "Epoch 18/20\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.7031 - accuracy: 0.3927\n",
            "Epoch 00018: val_accuracy improved from 0.39150 to 0.40400, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.7024 - accuracy: 0.3928 - val_loss: 1.6637 - val_accuracy: 0.4040\n",
            "Epoch 19/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.6876 - accuracy: 0.3959\n",
            "Epoch 00019: val_accuracy improved from 0.40400 to 0.41650, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.6876 - accuracy: 0.3959 - val_loss: 1.6270 - val_accuracy: 0.4165\n",
            "Epoch 20/20\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.6662 - accuracy: 0.4027\n",
            "Epoch 00020: val_accuracy improved from 0.41650 to 0.42160, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.6663 - accuracy: 0.4028 - val_loss: 1.6173 - val_accuracy: 0.4216\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5958 - accuracy: 0.4295\n",
            "0.429500013589859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSEbGFRJV9Da",
        "outputId": "ea1ee2a1-4108-496c-858d-51d1a383366a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "plt.plot(cnn_train_acc )\n",
        "plt.plot(sigmoid_train_acc )\n",
        "\n",
        "plt.title('Train Accuracy ')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Relu', 'Sigmoid'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_test_acc )\n",
        "plt.plot(sigmoid_test_acc )\n",
        "\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['ReLU', 'Sigmoid'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "print('best validation accuracy of ReLU:', cnn_best)\n",
        "print('best validation accuracy of sigmoid:', sigmoid_best)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best validation accuracy of Relu: 0.7347999811172485\n",
            "best validation accuracy of sigmoid: 0.429500013589859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQESTAxz2mB6"
      },
      "source": [
        "For part 2, the performance of sigmoid is terrible for the first few epochs and it is worse than Relu overall. I think the reason why it does not perform well at first is that it suffers from vanishing gradient. \\\\\n",
        "On the contrary, ReLU performs better in the early epochs because its activation has a gradient 0 or 1. It helps to reduce the influence of vanishing gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNHyKidBWzFT"
      },
      "source": [
        "#Part 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bZY9uz0kVz"
      },
      "source": [
        "# setup new constant for part3,4,5\n",
        "epochs = 40\n",
        "drop_out = True"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz9WeW20W1RW"
      },
      "source": [
        "def cnn_augmentation_dropout(x_train, y_train, x_test, y_test, data_augmentation = data_augmentation, drop_out = drop_out):\n",
        "  # Define a convolutional neural network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  if drop_out:\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  if drop_out:\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  if drop_out:\n",
        "    model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "  # Compile the model before using it\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  #print(model.summary())\n",
        "\n",
        "  # normalize the data\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  # partition training set into training and validation set\n",
        "  x_validate = x_train[40000:,:]\n",
        "  x_train = x_train[:40000,:]\n",
        "  y_validate = y_train[40000:,:]\n",
        "  y_train = y_train[:40000,:]\n",
        "\n",
        "  # create a callback that will save the best model while training\n",
        "  save_best_model = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  # train without data augmentation\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[save_best_model])\n",
        "\n",
        "  # train with data augmentation\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          callbacks=[save_best_model])\n",
        "  # Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "  saved_model = load_model('best_model.h5')\n",
        "  scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  cnn_train = history.history['accuracy']\n",
        "  cnn_test = history.history['val_accuracy']\n",
        "  return cnn_train, cnn_test, scores[1]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vphrwL11FXf",
        "outputId": "6eeabb30-522e-41e3-e761-547f743c4aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "aug_drop_train_acc, aug_drop_test_acc, aug_drop_best= cnn_augmentation_dropout(x_train, y_train, x_test, y_test, True, True)\n",
        "noaug_drop_train_acc, noaug_drop_test_acc, noaug_drop_best = cnn_augmentation_dropout(x_train, y_train, x_test, y_test, False, True)\n",
        "aug_nodrop_train_acc, aug_nodrop_test_acc, aug_nodrop_best = cnn_augmentation_dropout(x_train, y_train, x_test, y_test, True, False)\n",
        "noaug_nodrop_train_acc, noaug_nodrop_test_acc, noaug_nodrop_best = cnn_augmentation_dropout(x_train, y_train, x_test, y_test, False, False)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.8727 - accuracy: 0.3199\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.42720, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.8723 - accuracy: 0.3201 - val_loss: 1.6187 - val_accuracy: 0.4272\n",
            "Epoch 2/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.6297 - accuracy: 0.4095\n",
            "Epoch 00002: val_accuracy improved from 0.42720 to 0.45220, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 1.6293 - accuracy: 0.4096 - val_loss: 1.5236 - val_accuracy: 0.4522\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.5123 - accuracy: 0.4524\n",
            "Epoch 00003: val_accuracy improved from 0.45220 to 0.50000, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 1.5123 - accuracy: 0.4524 - val_loss: 1.3955 - val_accuracy: 0.5000\n",
            "Epoch 4/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.4132 - accuracy: 0.4907\n",
            "Epoch 00004: val_accuracy improved from 0.50000 to 0.53730, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.4131 - accuracy: 0.4908 - val_loss: 1.2666 - val_accuracy: 0.5373\n",
            "Epoch 5/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.3418 - accuracy: 0.5198\n",
            "Epoch 00005: val_accuracy improved from 0.53730 to 0.54540, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.3415 - accuracy: 0.5198 - val_loss: 1.2651 - val_accuracy: 0.5454\n",
            "Epoch 6/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.2807 - accuracy: 0.5401\n",
            "Epoch 00006: val_accuracy improved from 0.54540 to 0.59370, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.2809 - accuracy: 0.5401 - val_loss: 1.1403 - val_accuracy: 0.5937\n",
            "Epoch 7/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.2348 - accuracy: 0.5594\n",
            "Epoch 00007: val_accuracy improved from 0.59370 to 0.59750, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.2348 - accuracy: 0.5594 - val_loss: 1.1285 - val_accuracy: 0.5975\n",
            "Epoch 8/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.1897 - accuracy: 0.5778\n",
            "Epoch 00008: val_accuracy improved from 0.59750 to 0.62680, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1897 - accuracy: 0.5778 - val_loss: 1.0501 - val_accuracy: 0.6268\n",
            "Epoch 9/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.1526 - accuracy: 0.5904\n",
            "Epoch 00009: val_accuracy did not improve from 0.62680\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1524 - accuracy: 0.5905 - val_loss: 1.0506 - val_accuracy: 0.6266\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.1120 - accuracy: 0.6023\n",
            "Epoch 00010: val_accuracy improved from 0.62680 to 0.65700, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1120 - accuracy: 0.6023 - val_loss: 0.9686 - val_accuracy: 0.6570\n",
            "Epoch 11/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.0864 - accuracy: 0.6159\n",
            "Epoch 00011: val_accuracy did not improve from 0.65700\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0863 - accuracy: 0.6160 - val_loss: 1.0108 - val_accuracy: 0.6455\n",
            "Epoch 12/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.0618 - accuracy: 0.6242\n",
            "Epoch 00012: val_accuracy improved from 0.65700 to 0.66380, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0620 - accuracy: 0.6241 - val_loss: 0.9628 - val_accuracy: 0.6638\n",
            "Epoch 13/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.0354 - accuracy: 0.6355\n",
            "Epoch 00013: val_accuracy did not improve from 0.66380\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0357 - accuracy: 0.6354 - val_loss: 0.9772 - val_accuracy: 0.6501\n",
            "Epoch 14/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.0178 - accuracy: 0.6395\n",
            "Epoch 00014: val_accuracy improved from 0.66380 to 0.67200, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0176 - accuracy: 0.6397 - val_loss: 0.9298 - val_accuracy: 0.6720\n",
            "Epoch 15/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.9969 - accuracy: 0.6494\n",
            "Epoch 00015: val_accuracy improved from 0.67200 to 0.68770, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9969 - accuracy: 0.6494 - val_loss: 0.9060 - val_accuracy: 0.6877\n",
            "Epoch 16/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9890 - accuracy: 0.6532\n",
            "Epoch 00016: val_accuracy did not improve from 0.68770\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9888 - accuracy: 0.6533 - val_loss: 0.9252 - val_accuracy: 0.6807\n",
            "Epoch 17/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.9726 - accuracy: 0.6594\n",
            "Epoch 00017: val_accuracy improved from 0.68770 to 0.70460, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9726 - accuracy: 0.6594 - val_loss: 0.8658 - val_accuracy: 0.7046\n",
            "Epoch 18/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.9598 - accuracy: 0.6646\n",
            "Epoch 00018: val_accuracy improved from 0.70460 to 0.70670, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9598 - accuracy: 0.6647 - val_loss: 0.8393 - val_accuracy: 0.7067\n",
            "Epoch 19/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.9478 - accuracy: 0.6691\n",
            "Epoch 00019: val_accuracy did not improve from 0.70670\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9478 - accuracy: 0.6691 - val_loss: 0.8448 - val_accuracy: 0.7060\n",
            "Epoch 20/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9374 - accuracy: 0.6731\n",
            "Epoch 00020: val_accuracy improved from 0.70670 to 0.72430, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9374 - accuracy: 0.6731 - val_loss: 0.8060 - val_accuracy: 0.7243\n",
            "Epoch 21/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9245 - accuracy: 0.6776\n",
            "Epoch 00021: val_accuracy did not improve from 0.72430\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9245 - accuracy: 0.6776 - val_loss: 0.8216 - val_accuracy: 0.7197\n",
            "Epoch 22/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9170 - accuracy: 0.6797\n",
            "Epoch 00022: val_accuracy did not improve from 0.72430\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9171 - accuracy: 0.6796 - val_loss: 0.8284 - val_accuracy: 0.7155\n",
            "Epoch 23/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.9146 - accuracy: 0.6850\n",
            "Epoch 00023: val_accuracy did not improve from 0.72430\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9145 - accuracy: 0.6852 - val_loss: 0.8273 - val_accuracy: 0.7165\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.9017 - accuracy: 0.6894\n",
            "Epoch 00024: val_accuracy improved from 0.72430 to 0.72480, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9017 - accuracy: 0.6894 - val_loss: 0.8225 - val_accuracy: 0.7248\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8983 - accuracy: 0.6881\n",
            "Epoch 00025: val_accuracy improved from 0.72480 to 0.72780, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8983 - accuracy: 0.6881 - val_loss: 0.7967 - val_accuracy: 0.7278\n",
            "Epoch 26/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8874 - accuracy: 0.6912\n",
            "Epoch 00026: val_accuracy improved from 0.72780 to 0.74010, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8872 - accuracy: 0.6913 - val_loss: 0.7657 - val_accuracy: 0.7401\n",
            "Epoch 27/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8798 - accuracy: 0.6949\n",
            "Epoch 00027: val_accuracy did not improve from 0.74010\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8797 - accuracy: 0.6949 - val_loss: 0.7841 - val_accuracy: 0.7332\n",
            "Epoch 28/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8790 - accuracy: 0.6939\n",
            "Epoch 00028: val_accuracy did not improve from 0.74010\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.8789 - accuracy: 0.6941 - val_loss: 0.8637 - val_accuracy: 0.7117\n",
            "Epoch 29/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.8683 - accuracy: 0.7018\n",
            "Epoch 00029: val_accuracy improved from 0.74010 to 0.74280, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8684 - accuracy: 0.7017 - val_loss: 0.7555 - val_accuracy: 0.7428\n",
            "Epoch 30/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8661 - accuracy: 0.7019\n",
            "Epoch 00030: val_accuracy did not improve from 0.74280\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8659 - accuracy: 0.7020 - val_loss: 0.8829 - val_accuracy: 0.7110\n",
            "Epoch 31/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8614 - accuracy: 0.7059\n",
            "Epoch 00031: val_accuracy improved from 0.74280 to 0.74770, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8617 - accuracy: 0.7058 - val_loss: 0.7664 - val_accuracy: 0.7477\n",
            "Epoch 32/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8559 - accuracy: 0.7067\n",
            "Epoch 00032: val_accuracy did not improve from 0.74770\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8559 - accuracy: 0.7068 - val_loss: 0.8122 - val_accuracy: 0.7260\n",
            "Epoch 33/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8582 - accuracy: 0.7066\n",
            "Epoch 00033: val_accuracy did not improve from 0.74770\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8582 - accuracy: 0.7066 - val_loss: 0.7949 - val_accuracy: 0.7334\n",
            "Epoch 34/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8511 - accuracy: 0.7096\n",
            "Epoch 00034: val_accuracy did not improve from 0.74770\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8512 - accuracy: 0.7095 - val_loss: 0.7416 - val_accuracy: 0.7465\n",
            "Epoch 35/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.8465 - accuracy: 0.7111\n",
            "Epoch 00035: val_accuracy improved from 0.74770 to 0.75600, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8462 - accuracy: 0.7111 - val_loss: 0.7223 - val_accuracy: 0.7560\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8431 - accuracy: 0.7103\n",
            "Epoch 00036: val_accuracy did not improve from 0.75600\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8431 - accuracy: 0.7103 - val_loss: 0.7660 - val_accuracy: 0.7439\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8400 - accuracy: 0.7110\n",
            "Epoch 00037: val_accuracy did not improve from 0.75600\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8400 - accuracy: 0.7110 - val_loss: 0.7403 - val_accuracy: 0.7513\n",
            "Epoch 38/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8353 - accuracy: 0.7156\n",
            "Epoch 00038: val_accuracy did not improve from 0.75600\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8353 - accuracy: 0.7156 - val_loss: 0.7472 - val_accuracy: 0.7476\n",
            "Epoch 39/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8322 - accuracy: 0.7163\n",
            "Epoch 00039: val_accuracy improved from 0.75600 to 0.75610, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8324 - accuracy: 0.7161 - val_loss: 0.7397 - val_accuracy: 0.7561\n",
            "Epoch 40/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8266 - accuracy: 0.7158\n",
            "Epoch 00040: val_accuracy improved from 0.75610 to 0.76930, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8268 - accuracy: 0.7157 - val_loss: 0.7117 - val_accuracy: 0.7693\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7302 - accuracy: 0.7553\n",
            "Not using data augmentation.\n",
            "Epoch 1/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.8175 - accuracy: 0.3349\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.44930, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8171 - accuracy: 0.3350 - val_loss: 1.5316 - val_accuracy: 0.4493\n",
            "Epoch 2/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.5067 - accuracy: 0.4544\n",
            "Epoch 00002: val_accuracy improved from 0.44930 to 0.49620, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5069 - accuracy: 0.4542 - val_loss: 1.4112 - val_accuracy: 0.4962\n",
            "Epoch 3/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.3704 - accuracy: 0.5077\n",
            "Epoch 00003: val_accuracy improved from 0.49620 to 0.55290, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3704 - accuracy: 0.5078 - val_loss: 1.2595 - val_accuracy: 0.5529\n",
            "Epoch 4/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.2704 - accuracy: 0.5484\n",
            "Epoch 00004: val_accuracy improved from 0.55290 to 0.58140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2701 - accuracy: 0.5484 - val_loss: 1.1794 - val_accuracy: 0.5814\n",
            "Epoch 5/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.1970 - accuracy: 0.5752\n",
            "Epoch 00005: val_accuracy improved from 0.58140 to 0.60130, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1971 - accuracy: 0.5751 - val_loss: 1.1242 - val_accuracy: 0.6013\n",
            "Epoch 6/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.1299 - accuracy: 0.6000\n",
            "Epoch 00006: val_accuracy improved from 0.60130 to 0.61610, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1295 - accuracy: 0.6001 - val_loss: 1.0845 - val_accuracy: 0.6161\n",
            "Epoch 7/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.0742 - accuracy: 0.6219\n",
            "Epoch 00007: val_accuracy improved from 0.61610 to 0.63540, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0747 - accuracy: 0.6218 - val_loss: 1.0376 - val_accuracy: 0.6354\n",
            "Epoch 8/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.0240 - accuracy: 0.6402\n",
            "Epoch 00008: val_accuracy improved from 0.63540 to 0.66730, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0243 - accuracy: 0.6401 - val_loss: 0.9574 - val_accuracy: 0.6673\n",
            "Epoch 9/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9772 - accuracy: 0.6574\n",
            "Epoch 00009: val_accuracy improved from 0.66730 to 0.67970, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9776 - accuracy: 0.6573 - val_loss: 0.9229 - val_accuracy: 0.6797\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.9367 - accuracy: 0.6747\n",
            "Epoch 00010: val_accuracy improved from 0.67970 to 0.68020, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9367 - accuracy: 0.6747 - val_loss: 0.9095 - val_accuracy: 0.6802\n",
            "Epoch 11/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.9061 - accuracy: 0.6855\n",
            "Epoch 00011: val_accuracy improved from 0.68020 to 0.69280, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9062 - accuracy: 0.6852 - val_loss: 0.8837 - val_accuracy: 0.6928\n",
            "Epoch 12/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.8779 - accuracy: 0.6938\n",
            "Epoch 00012: val_accuracy improved from 0.69280 to 0.70200, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8774 - accuracy: 0.6939 - val_loss: 0.8576 - val_accuracy: 0.7020\n",
            "Epoch 13/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.8563 - accuracy: 0.7033\n",
            "Epoch 00013: val_accuracy improved from 0.70200 to 0.70680, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8563 - accuracy: 0.7033 - val_loss: 0.8523 - val_accuracy: 0.7068\n",
            "Epoch 14/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8335 - accuracy: 0.7117\n",
            "Epoch 00014: val_accuracy improved from 0.70680 to 0.72240, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8332 - accuracy: 0.7118 - val_loss: 0.8090 - val_accuracy: 0.7224\n",
            "Epoch 15/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.8112 - accuracy: 0.7202\n",
            "Epoch 00015: val_accuracy improved from 0.72240 to 0.72790, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8110 - accuracy: 0.7200 - val_loss: 0.7932 - val_accuracy: 0.7279\n",
            "Epoch 16/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7997 - accuracy: 0.7227\n",
            "Epoch 00016: val_accuracy improved from 0.72790 to 0.72970, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7995 - accuracy: 0.7228 - val_loss: 0.7825 - val_accuracy: 0.7297\n",
            "Epoch 17/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.7849 - accuracy: 0.7274\n",
            "Epoch 00017: val_accuracy improved from 0.72970 to 0.74130, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7852 - accuracy: 0.7273 - val_loss: 0.7613 - val_accuracy: 0.7413\n",
            "Epoch 18/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.7692 - accuracy: 0.7362\n",
            "Epoch 00018: val_accuracy did not improve from 0.74130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7696 - accuracy: 0.7362 - val_loss: 0.7635 - val_accuracy: 0.7377\n",
            "Epoch 19/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.7579 - accuracy: 0.7380\n",
            "Epoch 00019: val_accuracy did not improve from 0.74130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7586 - accuracy: 0.7379 - val_loss: 0.7722 - val_accuracy: 0.7366\n",
            "Epoch 20/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7440 - accuracy: 0.7433\n",
            "Epoch 00020: val_accuracy did not improve from 0.74130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7446 - accuracy: 0.7433 - val_loss: 0.7610 - val_accuracy: 0.7390\n",
            "Epoch 21/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.7375 - accuracy: 0.7486\n",
            "Epoch 00021: val_accuracy improved from 0.74130 to 0.74820, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7377 - accuracy: 0.7484 - val_loss: 0.7507 - val_accuracy: 0.7482\n",
            "Epoch 22/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.7500\n",
            "Epoch 00022: val_accuracy improved from 0.74820 to 0.74870, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7335 - accuracy: 0.7500 - val_loss: 0.7423 - val_accuracy: 0.7487\n",
            "Epoch 23/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 0.7185 - accuracy: 0.7547\n",
            "Epoch 00023: val_accuracy improved from 0.74870 to 0.75260, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7183 - accuracy: 0.7550 - val_loss: 0.7293 - val_accuracy: 0.7526\n",
            "Epoch 24/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.7166 - accuracy: 0.7561\n",
            "Epoch 00024: val_accuracy did not improve from 0.75260\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7165 - accuracy: 0.7562 - val_loss: 0.7251 - val_accuracy: 0.7524\n",
            "Epoch 25/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.7098 - accuracy: 0.7580\n",
            "Epoch 00025: val_accuracy improved from 0.75260 to 0.75860, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7102 - accuracy: 0.7578 - val_loss: 0.7302 - val_accuracy: 0.7586\n",
            "Epoch 26/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.7000 - accuracy: 0.7627\n",
            "Epoch 00026: val_accuracy did not improve from 0.75860\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7015 - accuracy: 0.7623 - val_loss: 0.7389 - val_accuracy: 0.7552\n",
            "Epoch 27/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.7647\n",
            "Epoch 00027: val_accuracy did not improve from 0.75860\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6961 - accuracy: 0.7646 - val_loss: 0.7306 - val_accuracy: 0.7567\n",
            "Epoch 28/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6994 - accuracy: 0.7624\n",
            "Epoch 00028: val_accuracy did not improve from 0.75860\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6986 - accuracy: 0.7627 - val_loss: 0.7358 - val_accuracy: 0.7545\n",
            "Epoch 29/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.7664\n",
            "Epoch 00029: val_accuracy improved from 0.75860 to 0.75970, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6900 - accuracy: 0.7664 - val_loss: 0.7311 - val_accuracy: 0.7597\n",
            "Epoch 30/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6874 - accuracy: 0.7682\n",
            "Epoch 00030: val_accuracy improved from 0.75970 to 0.76220, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6877 - accuracy: 0.7682 - val_loss: 0.7426 - val_accuracy: 0.7622\n",
            "Epoch 31/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6827 - accuracy: 0.7688\n",
            "Epoch 00031: val_accuracy improved from 0.76220 to 0.76380, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6825 - accuracy: 0.7689 - val_loss: 0.7095 - val_accuracy: 0.7638\n",
            "Epoch 32/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6813 - accuracy: 0.7725\n",
            "Epoch 00032: val_accuracy did not improve from 0.76380\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6812 - accuracy: 0.7724 - val_loss: 0.7377 - val_accuracy: 0.7585\n",
            "Epoch 33/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6734 - accuracy: 0.7727\n",
            "Epoch 00033: val_accuracy improved from 0.76380 to 0.76950, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6738 - accuracy: 0.7724 - val_loss: 0.7137 - val_accuracy: 0.7695\n",
            "Epoch 34/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.7741\n",
            "Epoch 00034: val_accuracy did not improve from 0.76950\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6708 - accuracy: 0.7741 - val_loss: 0.7326 - val_accuracy: 0.7568\n",
            "Epoch 35/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.7767\n",
            "Epoch 00035: val_accuracy did not improve from 0.76950\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6678 - accuracy: 0.7768 - val_loss: 0.6998 - val_accuracy: 0.7652\n",
            "Epoch 36/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.7765\n",
            "Epoch 00036: val_accuracy improved from 0.76950 to 0.77120, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6728 - accuracy: 0.7764 - val_loss: 0.6908 - val_accuracy: 0.7712\n",
            "Epoch 37/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6632 - accuracy: 0.7767\n",
            "Epoch 00037: val_accuracy did not improve from 0.77120\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6631 - accuracy: 0.7768 - val_loss: 0.7176 - val_accuracy: 0.7642\n",
            "Epoch 38/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6589 - accuracy: 0.7788\n",
            "Epoch 00038: val_accuracy did not improve from 0.77120\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6588 - accuracy: 0.7789 - val_loss: 0.6953 - val_accuracy: 0.7708\n",
            "Epoch 39/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6524 - accuracy: 0.7804\n",
            "Epoch 00039: val_accuracy did not improve from 0.77120\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6522 - accuracy: 0.7804 - val_loss: 0.7134 - val_accuracy: 0.7682\n",
            "Epoch 40/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6581 - accuracy: 0.7787\n",
            "Epoch 00040: val_accuracy did not improve from 0.77120\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6583 - accuracy: 0.7786 - val_loss: 0.7510 - val_accuracy: 0.7636\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.7674\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.7240 - accuracy: 0.3754\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.45280, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.7236 - accuracy: 0.3754 - val_loss: 1.5184 - val_accuracy: 0.4528\n",
            "Epoch 2/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.4517 - accuracy: 0.4769\n",
            "Epoch 00002: val_accuracy improved from 0.45280 to 0.53320, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.4515 - accuracy: 0.4769 - val_loss: 1.3214 - val_accuracy: 0.5332\n",
            "Epoch 3/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.3207 - accuracy: 0.5252\n",
            "Epoch 00003: val_accuracy improved from 0.53320 to 0.55030, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.3210 - accuracy: 0.5252 - val_loss: 1.2568 - val_accuracy: 0.5503\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.2221 - accuracy: 0.5655\n",
            "Epoch 00004: val_accuracy improved from 0.55030 to 0.58630, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.2221 - accuracy: 0.5655 - val_loss: 1.1810 - val_accuracy: 0.5863\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.1400 - accuracy: 0.5967\n",
            "Epoch 00005: val_accuracy improved from 0.58630 to 0.63910, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1400 - accuracy: 0.5967 - val_loss: 1.0291 - val_accuracy: 0.6391\n",
            "Epoch 6/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.0772 - accuracy: 0.6199\n",
            "Epoch 00006: val_accuracy did not improve from 0.63910\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0769 - accuracy: 0.6199 - val_loss: 1.1386 - val_accuracy: 0.6086\n",
            "Epoch 7/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.0272 - accuracy: 0.6374\n",
            "Epoch 00007: val_accuracy improved from 0.63910 to 0.66350, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0273 - accuracy: 0.6374 - val_loss: 0.9750 - val_accuracy: 0.6635\n",
            "Epoch 8/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.9861 - accuracy: 0.6513\n",
            "Epoch 00008: val_accuracy improved from 0.66350 to 0.68240, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9860 - accuracy: 0.6514 - val_loss: 0.9168 - val_accuracy: 0.6824\n",
            "Epoch 9/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.9541 - accuracy: 0.6676\n",
            "Epoch 00009: val_accuracy did not improve from 0.68240\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9540 - accuracy: 0.6676 - val_loss: 0.9388 - val_accuracy: 0.6790\n",
            "Epoch 10/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.9139 - accuracy: 0.6793\n",
            "Epoch 00010: val_accuracy improved from 0.68240 to 0.70170, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9142 - accuracy: 0.6791 - val_loss: 0.8654 - val_accuracy: 0.7017\n",
            "Epoch 11/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8851 - accuracy: 0.6906\n",
            "Epoch 00011: val_accuracy improved from 0.70170 to 0.71650, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8849 - accuracy: 0.6906 - val_loss: 0.8280 - val_accuracy: 0.7165\n",
            "Epoch 12/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8531 - accuracy: 0.6992\n",
            "Epoch 00012: val_accuracy did not improve from 0.71650\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8531 - accuracy: 0.6992 - val_loss: 0.8311 - val_accuracy: 0.7153\n",
            "Epoch 13/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8288 - accuracy: 0.7100\n",
            "Epoch 00013: val_accuracy improved from 0.71650 to 0.73090, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8288 - accuracy: 0.7100 - val_loss: 0.7872 - val_accuracy: 0.7309\n",
            "Epoch 14/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8036 - accuracy: 0.7180\n",
            "Epoch 00014: val_accuracy did not improve from 0.73090\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.8035 - accuracy: 0.7181 - val_loss: 0.8467 - val_accuracy: 0.7135\n",
            "Epoch 15/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.7792 - accuracy: 0.7278\n",
            "Epoch 00015: val_accuracy improved from 0.73090 to 0.73720, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7792 - accuracy: 0.7278 - val_loss: 0.7763 - val_accuracy: 0.7372\n",
            "Epoch 16/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.7339\n",
            "Epoch 00016: val_accuracy did not improve from 0.73720\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7577 - accuracy: 0.7339 - val_loss: 0.7845 - val_accuracy: 0.7342\n",
            "Epoch 17/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.7331 - accuracy: 0.7464\n",
            "Epoch 00017: val_accuracy improved from 0.73720 to 0.74260, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7332 - accuracy: 0.7463 - val_loss: 0.7657 - val_accuracy: 0.7426\n",
            "Epoch 18/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.7205 - accuracy: 0.7463\n",
            "Epoch 00018: val_accuracy improved from 0.74260 to 0.74840, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7205 - accuracy: 0.7462 - val_loss: 0.7522 - val_accuracy: 0.7484\n",
            "Epoch 19/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7051 - accuracy: 0.7535\n",
            "Epoch 00019: val_accuracy improved from 0.74840 to 0.75500, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7051 - accuracy: 0.7535 - val_loss: 0.7216 - val_accuracy: 0.7550\n",
            "Epoch 20/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.7596\n",
            "Epoch 00020: val_accuracy improved from 0.75500 to 0.76870, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.6860 - accuracy: 0.7596 - val_loss: 0.6826 - val_accuracy: 0.7687\n",
            "Epoch 21/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6690 - accuracy: 0.7685\n",
            "Epoch 00021: val_accuracy improved from 0.76870 to 0.77060, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.6687 - accuracy: 0.7686 - val_loss: 0.6784 - val_accuracy: 0.7706\n",
            "Epoch 22/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6528 - accuracy: 0.7734\n",
            "Epoch 00022: val_accuracy did not improve from 0.77060\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.6531 - accuracy: 0.7733 - val_loss: 0.6857 - val_accuracy: 0.7665\n",
            "Epoch 23/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6375 - accuracy: 0.7766\n",
            "Epoch 00023: val_accuracy did not improve from 0.77060\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.6371 - accuracy: 0.7767 - val_loss: 0.6990 - val_accuracy: 0.7656\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.7827\n",
            "Epoch 00024: val_accuracy improved from 0.77060 to 0.78570, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 0.6254 - accuracy: 0.7827 - val_loss: 0.6403 - val_accuracy: 0.7857\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.7867\n",
            "Epoch 00025: val_accuracy did not improve from 0.78570\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.6105 - accuracy: 0.7867 - val_loss: 0.6549 - val_accuracy: 0.7800\n",
            "Epoch 26/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5974 - accuracy: 0.7917\n",
            "Epoch 00026: val_accuracy did not improve from 0.78570\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5975 - accuracy: 0.7917 - val_loss: 0.6908 - val_accuracy: 0.7709\n",
            "Epoch 27/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.7948\n",
            "Epoch 00027: val_accuracy improved from 0.78570 to 0.79090, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5891 - accuracy: 0.7948 - val_loss: 0.6327 - val_accuracy: 0.7909\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.8004\n",
            "Epoch 00028: val_accuracy did not improve from 0.79090\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5744 - accuracy: 0.8004 - val_loss: 0.6589 - val_accuracy: 0.7784\n",
            "Epoch 29/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5624 - accuracy: 0.8040\n",
            "Epoch 00029: val_accuracy did not improve from 0.79090\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 0.5625 - accuracy: 0.8040 - val_loss: 0.6337 - val_accuracy: 0.7901\n",
            "Epoch 30/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.8090\n",
            "Epoch 00030: val_accuracy did not improve from 0.79090\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5499 - accuracy: 0.8090 - val_loss: 0.6410 - val_accuracy: 0.7884\n",
            "Epoch 31/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.8138\n",
            "Epoch 00031: val_accuracy did not improve from 0.79090\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5387 - accuracy: 0.8137 - val_loss: 0.6690 - val_accuracy: 0.7816\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5360 - accuracy: 0.8163\n",
            "Epoch 00032: val_accuracy improved from 0.79090 to 0.79470, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5360 - accuracy: 0.8163 - val_loss: 0.6206 - val_accuracy: 0.7947\n",
            "Epoch 33/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.8173\n",
            "Epoch 00033: val_accuracy improved from 0.79470 to 0.80310, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 0.5274 - accuracy: 0.8173 - val_loss: 0.5923 - val_accuracy: 0.8031\n",
            "Epoch 34/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.5217 - accuracy: 0.8195\n",
            "Epoch 00034: val_accuracy did not improve from 0.80310\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5215 - accuracy: 0.8196 - val_loss: 0.6234 - val_accuracy: 0.7921\n",
            "Epoch 35/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.8253\n",
            "Epoch 00035: val_accuracy did not improve from 0.80310\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5075 - accuracy: 0.8253 - val_loss: 0.6098 - val_accuracy: 0.7968\n",
            "Epoch 36/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4993 - accuracy: 0.8278\n",
            "Epoch 00036: val_accuracy improved from 0.80310 to 0.80340, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.4991 - accuracy: 0.8280 - val_loss: 0.5960 - val_accuracy: 0.8034\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4956 - accuracy: 0.8296\n",
            "Epoch 00037: val_accuracy did not improve from 0.80340\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.4956 - accuracy: 0.8296 - val_loss: 0.6965 - val_accuracy: 0.7830\n",
            "Epoch 38/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4892 - accuracy: 0.8294\n",
            "Epoch 00038: val_accuracy did not improve from 0.80340\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.4895 - accuracy: 0.8293 - val_loss: 0.6429 - val_accuracy: 0.7956\n",
            "Epoch 39/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.8358\n",
            "Epoch 00039: val_accuracy improved from 0.80340 to 0.81240, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 0.4801 - accuracy: 0.8358 - val_loss: 0.5775 - val_accuracy: 0.8124\n",
            "Epoch 40/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.8350\n",
            "Epoch 00040: val_accuracy did not improve from 0.81240\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.4745 - accuracy: 0.8350 - val_loss: 0.6060 - val_accuracy: 0.8058\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6099 - accuracy: 0.8039\n",
            "Not using data augmentation.\n",
            "Epoch 1/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.6709 - accuracy: 0.4018\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.49410, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.6697 - accuracy: 0.4024 - val_loss: 1.4283 - val_accuracy: 0.4941\n",
            "Epoch 2/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.3379 - accuracy: 0.5228\n",
            "Epoch 00002: val_accuracy improved from 0.49410 to 0.52860, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3379 - accuracy: 0.5228 - val_loss: 1.3486 - val_accuracy: 0.5286\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.1710 - accuracy: 0.5857\n",
            "Epoch 00003: val_accuracy improved from 0.52860 to 0.61400, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1710 - accuracy: 0.5857 - val_loss: 1.1212 - val_accuracy: 0.6140\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.0551 - accuracy: 0.6320\n",
            "Epoch 00004: val_accuracy improved from 0.61400 to 0.62300, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0551 - accuracy: 0.6320 - val_loss: 1.0852 - val_accuracy: 0.6230\n",
            "Epoch 5/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9657 - accuracy: 0.6641\n",
            "Epoch 00005: val_accuracy improved from 0.62300 to 0.64170, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9655 - accuracy: 0.6641 - val_loss: 1.0239 - val_accuracy: 0.6417\n",
            "Epoch 6/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.8891 - accuracy: 0.6918\n",
            "Epoch 00006: val_accuracy improved from 0.64170 to 0.67500, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8896 - accuracy: 0.6915 - val_loss: 0.9480 - val_accuracy: 0.6750\n",
            "Epoch 7/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.8233 - accuracy: 0.7130\n",
            "Epoch 00007: val_accuracy improved from 0.67500 to 0.68810, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8238 - accuracy: 0.7129 - val_loss: 0.9105 - val_accuracy: 0.6881\n",
            "Epoch 8/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.7607 - accuracy: 0.7366\n",
            "Epoch 00008: val_accuracy improved from 0.68810 to 0.69300, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7614 - accuracy: 0.7361 - val_loss: 0.8985 - val_accuracy: 0.6930\n",
            "Epoch 9/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.7065 - accuracy: 0.7563\n",
            "Epoch 00009: val_accuracy improved from 0.69300 to 0.69990, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7065 - accuracy: 0.7563 - val_loss: 0.8781 - val_accuracy: 0.6999\n",
            "Epoch 10/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6452 - accuracy: 0.7781\n",
            "Epoch 00010: val_accuracy improved from 0.69990 to 0.71180, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6452 - accuracy: 0.7782 - val_loss: 0.8548 - val_accuracy: 0.7118\n",
            "Epoch 11/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.5906 - accuracy: 0.7991\n",
            "Epoch 00011: val_accuracy did not improve from 0.71180\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5902 - accuracy: 0.7993 - val_loss: 0.8602 - val_accuracy: 0.7110\n",
            "Epoch 12/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.8181\n",
            "Epoch 00012: val_accuracy improved from 0.71180 to 0.72960, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5343 - accuracy: 0.8181 - val_loss: 0.8238 - val_accuracy: 0.7296\n",
            "Epoch 13/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.4793 - accuracy: 0.8378\n",
            "Epoch 00013: val_accuracy did not improve from 0.72960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4788 - accuracy: 0.8378 - val_loss: 0.8842 - val_accuracy: 0.7173\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8579\n",
            "Epoch 00014: val_accuracy did not improve from 0.72960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4246 - accuracy: 0.8579 - val_loss: 0.8541 - val_accuracy: 0.7292\n",
            "Epoch 15/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.3707 - accuracy: 0.8767\n",
            "Epoch 00015: val_accuracy did not improve from 0.72960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3706 - accuracy: 0.8766 - val_loss: 0.9641 - val_accuracy: 0.7134\n",
            "Epoch 16/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8940\n",
            "Epoch 00016: val_accuracy did not improve from 0.72960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3218 - accuracy: 0.8939 - val_loss: 0.9524 - val_accuracy: 0.7213\n",
            "Epoch 17/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.9115\n",
            "Epoch 00017: val_accuracy did not improve from 0.72960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2714 - accuracy: 0.9115 - val_loss: 0.9899 - val_accuracy: 0.7275\n",
            "Epoch 18/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9258\n",
            "Epoch 00018: val_accuracy did not improve from 0.72960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2285 - accuracy: 0.9258 - val_loss: 1.0345 - val_accuracy: 0.7282\n",
            "Epoch 19/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.1876 - accuracy: 0.9406\n",
            "Epoch 00019: val_accuracy did not improve from 0.72960\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1877 - accuracy: 0.9406 - val_loss: 1.0782 - val_accuracy: 0.7273\n",
            "Epoch 20/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.9513\n",
            "Epoch 00020: val_accuracy improved from 0.72960 to 0.72980, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1519 - accuracy: 0.9513 - val_loss: 1.1491 - val_accuracy: 0.7298\n",
            "Epoch 21/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9614\n",
            "Epoch 00021: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1240 - accuracy: 0.9615 - val_loss: 1.2700 - val_accuracy: 0.7266\n",
            "Epoch 22/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.9709\n",
            "Epoch 00022: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0977 - accuracy: 0.9707 - val_loss: 1.2834 - val_accuracy: 0.7292\n",
            "Epoch 23/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9772\n",
            "Epoch 00023: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0771 - accuracy: 0.9772 - val_loss: 1.4373 - val_accuracy: 0.7212\n",
            "Epoch 24/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9810\n",
            "Epoch 00024: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0632 - accuracy: 0.9810 - val_loss: 1.5195 - val_accuracy: 0.7214\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9846\n",
            "Epoch 00025: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 1.5666 - val_accuracy: 0.7246\n",
            "Epoch 26/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9883\n",
            "Epoch 00026: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0427 - accuracy: 0.9883 - val_loss: 1.6910 - val_accuracy: 0.7246\n",
            "Epoch 27/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9896\n",
            "Epoch 00027: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 1.6810 - val_accuracy: 0.7293\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9906\n",
            "Epoch 00028: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 1.8909 - val_accuracy: 0.7165\n",
            "Epoch 29/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9919\n",
            "Epoch 00029: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 1.9524 - val_accuracy: 0.7191\n",
            "Epoch 30/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9927\n",
            "Epoch 00030: val_accuracy did not improve from 0.72980\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 1.9966 - val_accuracy: 0.7209\n",
            "Epoch 31/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9933\n",
            "Epoch 00031: val_accuracy improved from 0.72980 to 0.73000, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 2.0377 - val_accuracy: 0.7300\n",
            "Epoch 32/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9939\n",
            "Epoch 00032: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 2.2611 - val_accuracy: 0.7175\n",
            "Epoch 33/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9941\n",
            "Epoch 00033: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 2.1853 - val_accuracy: 0.7270\n",
            "Epoch 34/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9946\n",
            "Epoch 00034: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 2.2348 - val_accuracy: 0.7262\n",
            "Epoch 35/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9955\n",
            "Epoch 00035: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 2.3478 - val_accuracy: 0.7252\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9951\n",
            "Epoch 00036: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 2.4392 - val_accuracy: 0.7168\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9954\n",
            "Epoch 00037: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 2.4831 - val_accuracy: 0.7184\n",
            "Epoch 38/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9958\n",
            "Epoch 00038: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 2.5002 - val_accuracy: 0.7177\n",
            "Epoch 39/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9966\n",
            "Epoch 00039: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 2.5566 - val_accuracy: 0.7243\n",
            "Epoch 40/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9960\n",
            "Epoch 00040: val_accuracy did not improve from 0.73000\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 2.5612 - val_accuracy: 0.7234\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.1949 - accuracy: 0.7210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfKRXou86YKI",
        "outputId": "ddca9a95-277a-4192-9593-968945e82bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "plt.plot(aug_drop_train_acc )\n",
        "plt.plot(aug_nodrop_train_acc )\n",
        "plt.plot(noaug_drop_train_acc )\n",
        "plt.plot(noaug_nodrop_train_acc )\n",
        "\n",
        "plt.title('Train Accuracy ')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Dropout and Aug', 'no Dropout, Aug', 'Dropout, no Aug', 'no Dropout, no Aug'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(aug_drop_test_acc )\n",
        "plt.plot(aug_nodrop_test_acc )\n",
        "plt.plot(noaug_drop_test_acc)\n",
        "plt.plot(noaug_nodrop_test_acc )\n",
        "\n",
        "plt.title('Validation Accuracy ')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Dropout and Aug', 'no Dropout, Aug', 'Dropout, no Aug', 'no Dropout, no Aug'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "print('best validation accuracy with dropout and augmentation:', aug_drop_best)\n",
        "print('best validation accuracy with only dropout:', noaug_drop_best)\n",
        "print('best validation accuracy with only augmentation:', aug_nodrop_best)\n",
        "print('best validation accuracy without dropout and augmentation:', noaug_nodrop_best)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best validation accuracy with dropout and augmentation: 0.755299985408783\n",
            "best validation accuracy with only dropout: 0.7674000263214111\n",
            "best validation accuracy with only augmentation: 0.8039000034332275\n",
            "best validation accuracy without dropout and augmentation: 0.7210000157356262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSQxL6fY7mZT"
      },
      "source": [
        "What I expect to see in the curve:  \\\\\n",
        "I think if we produce 100 epochs, the train accuracy will keep the trend of first 40 epochs. For the validation accuracy, the validation accuracy of cnn with only augmenation will be the highest. Validation accuracy of cnn without dropout and augmentation will be the worst. CNN with both dropout and augmentation performs better than cnn without dropout and augmentation, but it performs still not good enough. \\\\\n",
        "\n",
        "The reason why they performs like curve I describe above is that: cnn without dropout and augmentation overfits the training data, which leads it has the worst performance. \\\\\n",
        "cnn with both dropout and augmentation does not perform well because we add too much punishment to decrease the overfitting. This might influenced the validation accuracy.\\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T1Hlgqkbj5f"
      },
      "source": [
        "#Part 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnDhLM-4bpLy"
      },
      "source": [
        "def adam_cnn(x_train, y_train, x_test, y_test, data_augmentation=data_augmentation):\n",
        "  # Define a convolutional neural network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  # initiate adam optimizer\n",
        "  opt = keras.optimizers.Adam()\n",
        "\n",
        "  # Compile the model before using it\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  #print(model.summary())\n",
        "\n",
        "  # normalize the data\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  # partition training set into training and validation set\n",
        "  x_validate = x_train[40000:,:]\n",
        "  x_train = x_train[:40000,:]\n",
        "  y_validate = y_train[40000:,:]\n",
        "  y_train = y_train[:40000,:]\n",
        "\n",
        "  # create a callback that will save the best model while training\n",
        "  save_best_model = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  # train without data augmentation\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[save_best_model])\n",
        "\n",
        "  # train with data augmentation\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          callbacks=[save_best_model])\n",
        "  # Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "  saved_model = load_model('best_model.h5')\n",
        "  scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  adam_cnn_train = history.history['accuracy']\n",
        "  adam_cnn_test = history.history['val_accuracy']\n",
        "  return adam_cnn_train, adam_cnn_test, scores[1]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y756b6tKfFVd"
      },
      "source": [
        "def adagrad_cnn(x_train, y_train, x_test, y_test, data_augmentation=data_augmentation):\n",
        "  # Define a convolutional neural network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  # initiate adagrad optimizer\n",
        "  opt = keras.optimizers.Adagrad()\n",
        "\n",
        "  # Compile the model before using it\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "  # normalize the data\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  # partition training set into training and validation set\n",
        "  x_validate = x_train[40000:,:]\n",
        "  x_train = x_train[:40000,:]\n",
        "  y_validate = y_train[40000:,:]\n",
        "  y_train = y_train[:40000,:]\n",
        "\n",
        "  # create a callback that will save the best model while training\n",
        "  save_best_model = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  # train without data augmentation\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[save_best_model])\n",
        "\n",
        "  # train with data augmentation\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          callbacks=[save_best_model])\n",
        "      \n",
        "  # Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "  saved_model = load_model('best_model.h5')\n",
        "  scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  adagrad_cnn_train = history.history['accuracy']\n",
        "  adagrad_cnn_test = history.history['val_accuracy']\n",
        "  return adagrad_cnn_train, adagrad_cnn_test, scores[1]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1OPmoZLfUQu",
        "outputId": "3c90590c-4402-41d7-b4b0-c7c56c4315bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "adam_train_acc, adam_test_acc, adam_best = adam_cnn(x_train, y_train, x_test, y_test)\n",
        "adagrad_train_acc, adagrad_test_acc, adagrad_best = adagrad_cnn(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not using data augmentation.\n",
            "Epoch 1/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.5657 - accuracy: 0.4248\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.59840, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5644 - accuracy: 0.4252 - val_loss: 1.1391 - val_accuracy: 0.5984\n",
            "Epoch 2/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.1385 - accuracy: 0.5967\n",
            "Epoch 00002: val_accuracy improved from 0.59840 to 0.66740, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1381 - accuracy: 0.5969 - val_loss: 0.9415 - val_accuracy: 0.6674\n",
            "Epoch 3/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9925 - accuracy: 0.6484\n",
            "Epoch 00003: val_accuracy improved from 0.66740 to 0.68770, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9927 - accuracy: 0.6483 - val_loss: 0.8767 - val_accuracy: 0.6877\n",
            "Epoch 4/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.8821 - accuracy: 0.6918\n",
            "Epoch 00004: val_accuracy improved from 0.68770 to 0.70910, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8814 - accuracy: 0.6919 - val_loss: 0.8226 - val_accuracy: 0.7091\n",
            "Epoch 5/40\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 0.8056 - accuracy: 0.7181\n",
            "Epoch 00005: val_accuracy did not improve from 0.70910\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8065 - accuracy: 0.7178 - val_loss: 0.8476 - val_accuracy: 0.7048\n",
            "Epoch 6/40\n",
            "1238/1250 [============================>.] - ETA: 0s - loss: 0.7500 - accuracy: 0.7350\n",
            "Epoch 00006: val_accuracy improved from 0.70910 to 0.73890, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7493 - accuracy: 0.7352 - val_loss: 0.7433 - val_accuracy: 0.7389\n",
            "Epoch 7/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6997 - accuracy: 0.7533\n",
            "Epoch 00007: val_accuracy improved from 0.73890 to 0.75220, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7001 - accuracy: 0.7532 - val_loss: 0.7174 - val_accuracy: 0.7522\n",
            "Epoch 8/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6603 - accuracy: 0.7669\n",
            "Epoch 00008: val_accuracy improved from 0.75220 to 0.75490, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6601 - accuracy: 0.7670 - val_loss: 0.7054 - val_accuracy: 0.7549\n",
            "Epoch 9/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.6250 - accuracy: 0.7791\n",
            "Epoch 00009: val_accuracy improved from 0.75490 to 0.76310, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6252 - accuracy: 0.7791 - val_loss: 0.6881 - val_accuracy: 0.7631\n",
            "Epoch 10/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.7892\n",
            "Epoch 00010: val_accuracy did not improve from 0.76310\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6000 - accuracy: 0.7894 - val_loss: 0.6922 - val_accuracy: 0.7624\n",
            "Epoch 11/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.5608 - accuracy: 0.8011\n",
            "Epoch 00011: val_accuracy improved from 0.76310 to 0.76380, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5613 - accuracy: 0.8008 - val_loss: 0.6854 - val_accuracy: 0.7638\n",
            "Epoch 12/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.8090\n",
            "Epoch 00012: val_accuracy did not improve from 0.76380\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5373 - accuracy: 0.8088 - val_loss: 0.7013 - val_accuracy: 0.7628\n",
            "Epoch 13/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.5228 - accuracy: 0.8162\n",
            "Epoch 00013: val_accuracy improved from 0.76380 to 0.76770, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5227 - accuracy: 0.8162 - val_loss: 0.6927 - val_accuracy: 0.7677\n",
            "Epoch 14/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.4915 - accuracy: 0.8264\n",
            "Epoch 00014: val_accuracy did not improve from 0.76770\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4913 - accuracy: 0.8265 - val_loss: 0.7297 - val_accuracy: 0.7657\n",
            "Epoch 15/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 0.4785 - accuracy: 0.8315\n",
            "Epoch 00015: val_accuracy improved from 0.76770 to 0.77530, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4792 - accuracy: 0.8312 - val_loss: 0.6774 - val_accuracy: 0.7753\n",
            "Epoch 16/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.8343\n",
            "Epoch 00016: val_accuracy did not improve from 0.77530\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4706 - accuracy: 0.8342 - val_loss: 0.6795 - val_accuracy: 0.7740\n",
            "Epoch 17/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8407\n",
            "Epoch 00017: val_accuracy did not improve from 0.77530\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4509 - accuracy: 0.8407 - val_loss: 0.7142 - val_accuracy: 0.7726\n",
            "Epoch 18/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 0.4202 - accuracy: 0.8518\n",
            "Epoch 00018: val_accuracy did not improve from 0.77530\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4203 - accuracy: 0.8517 - val_loss: 0.7158 - val_accuracy: 0.7700\n",
            "Epoch 19/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8513\n",
            "Epoch 00019: val_accuracy did not improve from 0.77530\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4219 - accuracy: 0.8513 - val_loss: 0.7564 - val_accuracy: 0.7588\n",
            "Epoch 20/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4141 - accuracy: 0.8532\n",
            "Epoch 00020: val_accuracy did not improve from 0.77530\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4143 - accuracy: 0.8532 - val_loss: 0.7023 - val_accuracy: 0.7692\n",
            "Epoch 21/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.3977 - accuracy: 0.8606\n",
            "Epoch 00021: val_accuracy improved from 0.77530 to 0.77690, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3975 - accuracy: 0.8607 - val_loss: 0.7142 - val_accuracy: 0.7769\n",
            "Epoch 22/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.3926 - accuracy: 0.8621\n",
            "Epoch 00022: val_accuracy did not improve from 0.77690\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3924 - accuracy: 0.8622 - val_loss: 0.7321 - val_accuracy: 0.7746\n",
            "Epoch 23/40\n",
            "1238/1250 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8612\n",
            "Epoch 00023: val_accuracy did not improve from 0.77690\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3892 - accuracy: 0.8611 - val_loss: 0.7260 - val_accuracy: 0.7742\n",
            "Epoch 24/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.8683\n",
            "Epoch 00024: val_accuracy improved from 0.77690 to 0.78330, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3722 - accuracy: 0.8684 - val_loss: 0.6915 - val_accuracy: 0.7833\n",
            "Epoch 25/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8720\n",
            "Epoch 00025: val_accuracy did not improve from 0.78330\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3648 - accuracy: 0.8717 - val_loss: 0.7424 - val_accuracy: 0.7770\n",
            "Epoch 26/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.8727\n",
            "Epoch 00026: val_accuracy did not improve from 0.78330\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3643 - accuracy: 0.8726 - val_loss: 0.7837 - val_accuracy: 0.7739\n",
            "Epoch 27/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.3560 - accuracy: 0.8773\n",
            "Epoch 00027: val_accuracy improved from 0.78330 to 0.78560, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3560 - accuracy: 0.8771 - val_loss: 0.7186 - val_accuracy: 0.7856\n",
            "Epoch 28/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.8772\n",
            "Epoch 00028: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3519 - accuracy: 0.8771 - val_loss: 0.7713 - val_accuracy: 0.7748\n",
            "Epoch 29/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.8817\n",
            "Epoch 00029: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3441 - accuracy: 0.8817 - val_loss: 0.7475 - val_accuracy: 0.7779\n",
            "Epoch 30/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.8824\n",
            "Epoch 00030: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3402 - accuracy: 0.8823 - val_loss: 0.7614 - val_accuracy: 0.7839\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.8821\n",
            "Epoch 00031: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3362 - accuracy: 0.8821 - val_loss: 0.7718 - val_accuracy: 0.7756\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.8857\n",
            "Epoch 00032: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3292 - accuracy: 0.8857 - val_loss: 0.7417 - val_accuracy: 0.7771\n",
            "Epoch 33/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.3238 - accuracy: 0.8876\n",
            "Epoch 00033: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3234 - accuracy: 0.8878 - val_loss: 0.7973 - val_accuracy: 0.7830\n",
            "Epoch 34/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.8885\n",
            "Epoch 00034: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3229 - accuracy: 0.8885 - val_loss: 0.7544 - val_accuracy: 0.7770\n",
            "Epoch 35/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.3129 - accuracy: 0.8926\n",
            "Epoch 00035: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3130 - accuracy: 0.8926 - val_loss: 0.7806 - val_accuracy: 0.7768\n",
            "Epoch 36/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.8905\n",
            "Epoch 00036: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3150 - accuracy: 0.8905 - val_loss: 0.7839 - val_accuracy: 0.7789\n",
            "Epoch 37/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.3018 - accuracy: 0.8952\n",
            "Epoch 00037: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3023 - accuracy: 0.8950 - val_loss: 0.7627 - val_accuracy: 0.7790\n",
            "Epoch 38/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.8929\n",
            "Epoch 00038: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3142 - accuracy: 0.8929 - val_loss: 0.7615 - val_accuracy: 0.7814\n",
            "Epoch 39/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.8948\n",
            "Epoch 00039: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3072 - accuracy: 0.8951 - val_loss: 0.7782 - val_accuracy: 0.7729\n",
            "Epoch 40/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.8991\n",
            "Epoch 00040: val_accuracy did not improve from 0.78560\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2950 - accuracy: 0.8991 - val_loss: 0.8118 - val_accuracy: 0.7791\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7605 - accuracy: 0.7768\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,168,362\n",
            "Trainable params: 2,168,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 2.2792 - accuracy: 0.1252\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.20410, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.2788 - accuracy: 0.1251 - val_loss: 2.2117 - val_accuracy: 0.2041\n",
            "Epoch 2/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 2.0935 - accuracy: 0.2225\n",
            "Epoch 00002: val_accuracy improved from 0.20410 to 0.27950, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0936 - accuracy: 0.2226 - val_loss: 1.9972 - val_accuracy: 0.2795\n",
            "Epoch 3/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.9964 - accuracy: 0.2684\n",
            "Epoch 00003: val_accuracy improved from 0.27950 to 0.30070, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9965 - accuracy: 0.2684 - val_loss: 1.9464 - val_accuracy: 0.3007\n",
            "Epoch 4/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.9513 - accuracy: 0.2884\n",
            "Epoch 00004: val_accuracy improved from 0.30070 to 0.32440, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9515 - accuracy: 0.2884 - val_loss: 1.9043 - val_accuracy: 0.3244\n",
            "Epoch 5/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.9097 - accuracy: 0.3077\n",
            "Epoch 00005: val_accuracy improved from 0.32440 to 0.34140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9096 - accuracy: 0.3078 - val_loss: 1.8632 - val_accuracy: 0.3414\n",
            "Epoch 6/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.8708 - accuracy: 0.3260\n",
            "Epoch 00006: val_accuracy improved from 0.34140 to 0.36150, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8707 - accuracy: 0.3259 - val_loss: 1.8209 - val_accuracy: 0.3615\n",
            "Epoch 7/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.8215 - accuracy: 0.3439\n",
            "Epoch 00007: val_accuracy improved from 0.36150 to 0.38150, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8213 - accuracy: 0.3438 - val_loss: 1.7607 - val_accuracy: 0.3815\n",
            "Epoch 8/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.7656 - accuracy: 0.3652\n",
            "Epoch 00008: val_accuracy improved from 0.38150 to 0.39980, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7657 - accuracy: 0.3652 - val_loss: 1.7041 - val_accuracy: 0.3998\n",
            "Epoch 9/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.7239 - accuracy: 0.3801\n",
            "Epoch 00009: val_accuracy improved from 0.39980 to 0.40730, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7238 - accuracy: 0.3801 - val_loss: 1.6690 - val_accuracy: 0.4073\n",
            "Epoch 10/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.6955 - accuracy: 0.3866\n",
            "Epoch 00010: val_accuracy improved from 0.40730 to 0.41700, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6953 - accuracy: 0.3868 - val_loss: 1.6405 - val_accuracy: 0.4170\n",
            "Epoch 11/40\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.6661 - accuracy: 0.3975\n",
            "Epoch 00011: val_accuracy improved from 0.41700 to 0.42370, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6657 - accuracy: 0.3976 - val_loss: 1.6115 - val_accuracy: 0.4237\n",
            "Epoch 12/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.6426 - accuracy: 0.4044\n",
            "Epoch 00012: val_accuracy improved from 0.42370 to 0.43070, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6425 - accuracy: 0.4044 - val_loss: 1.5903 - val_accuracy: 0.4307\n",
            "Epoch 13/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.6239 - accuracy: 0.4130\n",
            "Epoch 00013: val_accuracy improved from 0.43070 to 0.43940, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6238 - accuracy: 0.4130 - val_loss: 1.5648 - val_accuracy: 0.4394\n",
            "Epoch 14/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.6077 - accuracy: 0.4158\n",
            "Epoch 00014: val_accuracy improved from 0.43940 to 0.44180, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6079 - accuracy: 0.4157 - val_loss: 1.5529 - val_accuracy: 0.4418\n",
            "Epoch 15/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.5926 - accuracy: 0.4238\n",
            "Epoch 00015: val_accuracy improved from 0.44180 to 0.44680, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5926 - accuracy: 0.4239 - val_loss: 1.5411 - val_accuracy: 0.4468\n",
            "Epoch 16/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.5788 - accuracy: 0.4297\n",
            "Epoch 00016: val_accuracy improved from 0.44680 to 0.45260, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5790 - accuracy: 0.4296 - val_loss: 1.5248 - val_accuracy: 0.4526\n",
            "Epoch 17/40\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 1.5652 - accuracy: 0.4335\n",
            "Epoch 00017: val_accuracy improved from 0.45260 to 0.45690, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5652 - accuracy: 0.4334 - val_loss: 1.5123 - val_accuracy: 0.4569\n",
            "Epoch 18/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.5583 - accuracy: 0.4370\n",
            "Epoch 00018: val_accuracy improved from 0.45690 to 0.45950, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5578 - accuracy: 0.4374 - val_loss: 1.5037 - val_accuracy: 0.4595\n",
            "Epoch 19/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.5451 - accuracy: 0.4407\n",
            "Epoch 00019: val_accuracy improved from 0.45950 to 0.46290, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5447 - accuracy: 0.4408 - val_loss: 1.4912 - val_accuracy: 0.4629\n",
            "Epoch 20/40\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.5365 - accuracy: 0.4432\n",
            "Epoch 00020: val_accuracy improved from 0.46290 to 0.46680, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5371 - accuracy: 0.4428 - val_loss: 1.4854 - val_accuracy: 0.4668\n",
            "Epoch 21/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.5274 - accuracy: 0.4504\n",
            "Epoch 00021: val_accuracy improved from 0.46680 to 0.47090, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5274 - accuracy: 0.4503 - val_loss: 1.4724 - val_accuracy: 0.4709\n",
            "Epoch 22/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.5201 - accuracy: 0.4509\n",
            "Epoch 00022: val_accuracy improved from 0.47090 to 0.47590, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5200 - accuracy: 0.4511 - val_loss: 1.4676 - val_accuracy: 0.4759\n",
            "Epoch 23/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.5097 - accuracy: 0.4541\n",
            "Epoch 00023: val_accuracy improved from 0.47590 to 0.47840, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5092 - accuracy: 0.4544 - val_loss: 1.4537 - val_accuracy: 0.4784\n",
            "Epoch 24/40\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.5051 - accuracy: 0.4577\n",
            "Epoch 00024: val_accuracy improved from 0.47840 to 0.47890, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5043 - accuracy: 0.4581 - val_loss: 1.4519 - val_accuracy: 0.4789\n",
            "Epoch 25/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.4979 - accuracy: 0.4574\n",
            "Epoch 00025: val_accuracy improved from 0.47890 to 0.48400, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4978 - accuracy: 0.4575 - val_loss: 1.4430 - val_accuracy: 0.4840\n",
            "Epoch 26/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.4886 - accuracy: 0.4647\n",
            "Epoch 00026: val_accuracy improved from 0.48400 to 0.48700, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4886 - accuracy: 0.4647 - val_loss: 1.4380 - val_accuracy: 0.4870\n",
            "Epoch 27/40\n",
            "1239/1250 [============================>.] - ETA: 0s - loss: 1.4817 - accuracy: 0.4674\n",
            "Epoch 00027: val_accuracy improved from 0.48700 to 0.48980, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4817 - accuracy: 0.4673 - val_loss: 1.4281 - val_accuracy: 0.4898\n",
            "Epoch 28/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.4739 - accuracy: 0.4679\n",
            "Epoch 00028: val_accuracy improved from 0.48980 to 0.49140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4739 - accuracy: 0.4679 - val_loss: 1.4247 - val_accuracy: 0.4914\n",
            "Epoch 29/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.4721 - accuracy: 0.4686\n",
            "Epoch 00029: val_accuracy improved from 0.49140 to 0.49330, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4725 - accuracy: 0.4685 - val_loss: 1.4196 - val_accuracy: 0.4933\n",
            "Epoch 30/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.4617 - accuracy: 0.4733\n",
            "Epoch 00030: val_accuracy improved from 0.49330 to 0.49740, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4619 - accuracy: 0.4729 - val_loss: 1.4137 - val_accuracy: 0.4974\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.4548 - accuracy: 0.4746\n",
            "Epoch 00031: val_accuracy improved from 0.49740 to 0.50260, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4548 - accuracy: 0.4746 - val_loss: 1.4042 - val_accuracy: 0.5026\n",
            "Epoch 32/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.4495 - accuracy: 0.4772\n",
            "Epoch 00032: val_accuracy improved from 0.50260 to 0.50380, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4490 - accuracy: 0.4775 - val_loss: 1.3953 - val_accuracy: 0.5038\n",
            "Epoch 33/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.4401 - accuracy: 0.4824\n",
            "Epoch 00033: val_accuracy improved from 0.50380 to 0.50880, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4398 - accuracy: 0.4825 - val_loss: 1.3865 - val_accuracy: 0.5088\n",
            "Epoch 34/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.4344 - accuracy: 0.4841\n",
            "Epoch 00034: val_accuracy improved from 0.50880 to 0.51190, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4343 - accuracy: 0.4841 - val_loss: 1.3821 - val_accuracy: 0.5119\n",
            "Epoch 35/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.4248 - accuracy: 0.4847\n",
            "Epoch 00035: val_accuracy improved from 0.51190 to 0.51480, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4248 - accuracy: 0.4848 - val_loss: 1.3720 - val_accuracy: 0.5148\n",
            "Epoch 36/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.4168 - accuracy: 0.4916\n",
            "Epoch 00036: val_accuracy improved from 0.51480 to 0.51510, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4164 - accuracy: 0.4916 - val_loss: 1.3705 - val_accuracy: 0.5151\n",
            "Epoch 37/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.4124 - accuracy: 0.4890\n",
            "Epoch 00037: val_accuracy improved from 0.51510 to 0.51980, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4123 - accuracy: 0.4891 - val_loss: 1.3567 - val_accuracy: 0.5198\n",
            "Epoch 38/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.4064 - accuracy: 0.4945\n",
            "Epoch 00038: val_accuracy improved from 0.51980 to 0.52140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4066 - accuracy: 0.4945 - val_loss: 1.3523 - val_accuracy: 0.5214\n",
            "Epoch 39/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.4015 - accuracy: 0.4941\n",
            "Epoch 00039: val_accuracy improved from 0.52140 to 0.52450, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4015 - accuracy: 0.4941 - val_loss: 1.3516 - val_accuracy: 0.5245\n",
            "Epoch 40/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.4992\n",
            "Epoch 00040: val_accuracy improved from 0.52450 to 0.52640, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3892 - accuracy: 0.4992 - val_loss: 1.3416 - val_accuracy: 0.5264\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3220 - accuracy: 0.5325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ3Y7tzegvXW",
        "outputId": "17bf1f6d-1c94-4733-e25f-682d19de81d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "RMSprop_train_acc, RMSprop_test_acc, RMSprop_best = cnn(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,168,362\n",
            "Trainable params: 2,168,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.8102 - accuracy: 0.3391\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.45100, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8090 - accuracy: 0.3396 - val_loss: 1.5366 - val_accuracy: 0.4510\n",
            "Epoch 2/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.5085 - accuracy: 0.4536\n",
            "Epoch 00002: val_accuracy improved from 0.45100 to 0.52000, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5084 - accuracy: 0.4536 - val_loss: 1.3641 - val_accuracy: 0.5200\n",
            "Epoch 3/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.3511 - accuracy: 0.5141\n",
            "Epoch 00003: val_accuracy improved from 0.52000 to 0.56140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3507 - accuracy: 0.5142 - val_loss: 1.2446 - val_accuracy: 0.5614\n",
            "Epoch 4/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 1.2449 - accuracy: 0.5567\n",
            "Epoch 00004: val_accuracy improved from 0.56140 to 0.60450, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2449 - accuracy: 0.5568 - val_loss: 1.1340 - val_accuracy: 0.6045\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.1594 - accuracy: 0.5892\n",
            "Epoch 00005: val_accuracy improved from 0.60450 to 0.62140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1594 - accuracy: 0.5892 - val_loss: 1.0824 - val_accuracy: 0.6214\n",
            "Epoch 6/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.0936 - accuracy: 0.6139\n",
            "Epoch 00006: val_accuracy improved from 0.62140 to 0.64370, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0936 - accuracy: 0.6140 - val_loss: 1.0151 - val_accuracy: 0.6437\n",
            "Epoch 7/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 1.0356 - accuracy: 0.6364\n",
            "Epoch 00007: val_accuracy improved from 0.64370 to 0.65170, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0360 - accuracy: 0.6364 - val_loss: 1.0006 - val_accuracy: 0.6517\n",
            "Epoch 8/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.9910 - accuracy: 0.6523\n",
            "Epoch 00008: val_accuracy improved from 0.65170 to 0.67120, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9913 - accuracy: 0.6524 - val_loss: 0.9365 - val_accuracy: 0.6712\n",
            "Epoch 9/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.9542 - accuracy: 0.6678\n",
            "Epoch 00009: val_accuracy improved from 0.67120 to 0.67920, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9542 - accuracy: 0.6678 - val_loss: 0.9064 - val_accuracy: 0.6792\n",
            "Epoch 10/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.9196 - accuracy: 0.6789\n",
            "Epoch 00010: val_accuracy improved from 0.67920 to 0.68340, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9198 - accuracy: 0.6787 - val_loss: 0.9110 - val_accuracy: 0.6834\n",
            "Epoch 11/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.8937 - accuracy: 0.6886\n",
            "Epoch 00011: val_accuracy improved from 0.68340 to 0.70060, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8935 - accuracy: 0.6886 - val_loss: 0.8504 - val_accuracy: 0.7006\n",
            "Epoch 12/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.8634 - accuracy: 0.6991\n",
            "Epoch 00012: val_accuracy did not improve from 0.70060\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8636 - accuracy: 0.6991 - val_loss: 0.8726 - val_accuracy: 0.6940\n",
            "Epoch 13/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.8440 - accuracy: 0.7075\n",
            "Epoch 00013: val_accuracy improved from 0.70060 to 0.70890, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8439 - accuracy: 0.7075 - val_loss: 0.8360 - val_accuracy: 0.7089\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8222 - accuracy: 0.7129\n",
            "Epoch 00014: val_accuracy improved from 0.70890 to 0.71970, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8222 - accuracy: 0.7129 - val_loss: 0.8180 - val_accuracy: 0.7197\n",
            "Epoch 15/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8123 - accuracy: 0.7176\n",
            "Epoch 00015: val_accuracy improved from 0.71970 to 0.72590, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8125 - accuracy: 0.7176 - val_loss: 0.7916 - val_accuracy: 0.7259\n",
            "Epoch 16/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.7933 - accuracy: 0.7238\n",
            "Epoch 00016: val_accuracy improved from 0.72590 to 0.72620, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7937 - accuracy: 0.7236 - val_loss: 0.8043 - val_accuracy: 0.7262\n",
            "Epoch 17/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.7802 - accuracy: 0.7274\n",
            "Epoch 00017: val_accuracy improved from 0.72620 to 0.73010, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7799 - accuracy: 0.7274 - val_loss: 0.7798 - val_accuracy: 0.7301\n",
            "Epoch 18/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.7667 - accuracy: 0.7345\n",
            "Epoch 00018: val_accuracy improved from 0.73010 to 0.73540, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7669 - accuracy: 0.7345 - val_loss: 0.7786 - val_accuracy: 0.7354\n",
            "Epoch 19/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7503 - accuracy: 0.7437\n",
            "Epoch 00019: val_accuracy did not improve from 0.73540\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7508 - accuracy: 0.7435 - val_loss: 0.7821 - val_accuracy: 0.7320\n",
            "Epoch 20/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7432 - accuracy: 0.7445\n",
            "Epoch 00020: val_accuracy improved from 0.73540 to 0.73700, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7436 - accuracy: 0.7445 - val_loss: 0.7708 - val_accuracy: 0.7370\n",
            "Epoch 21/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7359 - accuracy: 0.7483\n",
            "Epoch 00021: val_accuracy improved from 0.73700 to 0.74010, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7359 - accuracy: 0.7483 - val_loss: 0.7477 - val_accuracy: 0.7401\n",
            "Epoch 22/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7198 - accuracy: 0.7506\n",
            "Epoch 00022: val_accuracy improved from 0.74010 to 0.74200, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7196 - accuracy: 0.7507 - val_loss: 0.7530 - val_accuracy: 0.7420\n",
            "Epoch 23/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.7579\n",
            "Epoch 00023: val_accuracy improved from 0.74200 to 0.74880, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7105 - accuracy: 0.7577 - val_loss: 0.7376 - val_accuracy: 0.7488\n",
            "Epoch 24/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7092 - accuracy: 0.7586\n",
            "Epoch 00024: val_accuracy did not improve from 0.74880\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7092 - accuracy: 0.7586 - val_loss: 0.7667 - val_accuracy: 0.7398\n",
            "Epoch 25/40\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.7001 - accuracy: 0.7617\n",
            "Epoch 00025: val_accuracy did not improve from 0.74880\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7002 - accuracy: 0.7616 - val_loss: 0.7461 - val_accuracy: 0.7476\n",
            "Epoch 26/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.7653\n",
            "Epoch 00026: val_accuracy did not improve from 0.74880\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6942 - accuracy: 0.7653 - val_loss: 0.7431 - val_accuracy: 0.7449\n",
            "Epoch 27/40\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.7655\n",
            "Epoch 00027: val_accuracy improved from 0.74880 to 0.75110, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6860 - accuracy: 0.7658 - val_loss: 0.7270 - val_accuracy: 0.7511\n",
            "Epoch 28/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6829 - accuracy: 0.7690\n",
            "Epoch 00028: val_accuracy did not improve from 0.75110\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6827 - accuracy: 0.7690 - val_loss: 0.7263 - val_accuracy: 0.7492\n",
            "Epoch 29/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6767 - accuracy: 0.7705\n",
            "Epoch 00029: val_accuracy improved from 0.75110 to 0.75830, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6771 - accuracy: 0.7703 - val_loss: 0.7274 - val_accuracy: 0.7583\n",
            "Epoch 30/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.7738\n",
            "Epoch 00030: val_accuracy did not improve from 0.75830\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6774 - accuracy: 0.7737 - val_loss: 0.7468 - val_accuracy: 0.7576\n",
            "Epoch 31/40\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.7727\n",
            "Epoch 00031: val_accuracy improved from 0.75830 to 0.76020, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6705 - accuracy: 0.7729 - val_loss: 0.7095 - val_accuracy: 0.7602\n",
            "Epoch 32/40\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6627 - accuracy: 0.7782\n",
            "Epoch 00032: val_accuracy improved from 0.76020 to 0.76310, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6629 - accuracy: 0.7781 - val_loss: 0.7285 - val_accuracy: 0.7631\n",
            "Epoch 33/40\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6621 - accuracy: 0.7762\n",
            "Epoch 00033: val_accuracy did not improve from 0.76310\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6621 - accuracy: 0.7761 - val_loss: 0.7446 - val_accuracy: 0.7544\n",
            "Epoch 34/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6577 - accuracy: 0.7770\n",
            "Epoch 00034: val_accuracy did not improve from 0.76310\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6580 - accuracy: 0.7768 - val_loss: 0.7347 - val_accuracy: 0.7597\n",
            "Epoch 35/40\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6529 - accuracy: 0.7803\n",
            "Epoch 00035: val_accuracy did not improve from 0.76310\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6530 - accuracy: 0.7802 - val_loss: 0.7272 - val_accuracy: 0.7607\n",
            "Epoch 36/40\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6513 - accuracy: 0.7813\n",
            "Epoch 00036: val_accuracy improved from 0.76310 to 0.76600, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6511 - accuracy: 0.7814 - val_loss: 0.7055 - val_accuracy: 0.7660\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.7844\n",
            "Epoch 00037: val_accuracy did not improve from 0.76600\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6497 - accuracy: 0.7844 - val_loss: 0.7269 - val_accuracy: 0.7584\n",
            "Epoch 38/40\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6486 - accuracy: 0.7838\n",
            "Epoch 00038: val_accuracy improved from 0.76600 to 0.76800, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6481 - accuracy: 0.7839 - val_loss: 0.7007 - val_accuracy: 0.7680\n",
            "Epoch 39/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6427 - accuracy: 0.7857\n",
            "Epoch 00039: val_accuracy improved from 0.76800 to 0.76910, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6431 - accuracy: 0.7855 - val_loss: 0.7143 - val_accuracy: 0.7691\n",
            "Epoch 40/40\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6400 - accuracy: 0.7874\n",
            "Epoch 00040: val_accuracy did not improve from 0.76910\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6403 - accuracy: 0.7872 - val_loss: 0.7253 - val_accuracy: 0.7676\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7348 - accuracy: 0.7629\n",
            "[0.7348220348358154, 0.7628999948501587]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhKaIZu_gMdh",
        "outputId": "95605da8-f4b4-48dc-c368-e2a1b31c4cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "plt.plot(adam_train_acc )\n",
        "plt.plot(adagrad_train_acc )\n",
        "plt.plot(RMSprop_train_acc )\n",
        "\n",
        "plt.title('Train Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Adam', 'Adagrad', 'RMSProp'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot( adam_test_acc )\n",
        "plt.plot( adagrad_test_acc )\n",
        "plt.plot( RMSprop_test_acc )\n",
        "\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Adam', 'Adagrad', 'RMSProp'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "print('best validation accuracy of RMSprop:', RMSprop_best)\n",
        "print('best validation accuracy of adam:', adam_best)\n",
        "print('best validation accuracy of adagrad:', adagrad_best)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best validation accuracy of RMSprop: 0.7628999948501587\n",
            "best validation accuracy of adam: 0.7767999768257141\n",
            "best validation accuracy of adagrad: 0.5325000286102295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTGPjALwG07I"
      },
      "source": [
        "For part 4, the curve I expect to see until epochs is 100 is: adam performs the best and adagrad, RMSprop converge to Adam. \\\\\n",
        "The reason why I expect adagrad becomes better later because adagrad is an optimizer as it has a low learning rate that is too small leads to painfully slow convergence. But overall it should be a better optimizer than RMSprop. \\\\\n",
        "For Adam optimizer, I think it performs better than RMSProp all the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5saMRv0nF8A"
      },
      "source": [
        "#Part 5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l1r_jCknIDQ"
      },
      "source": [
        "def cnn_5x5(x_train, y_train, x_test, y_test, data_augmentation=data_augmentation):\n",
        "  # Define a convolutional neural network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (5, 5), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (5, 5), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (5, 5), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (5, 5), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "  # Compile the model before using it\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "  # normalize the data\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  # partition training set into training and validation set\n",
        "  x_validate = x_train[40000:,:]\n",
        "  x_train = x_train[:40000,:]\n",
        "  y_validate = y_train[40000:,:]\n",
        "  y_train = y_train[:40000,:]\n",
        "\n",
        "  # create a callback that will save the best model while training\n",
        "  save_best_model = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "  # train without data augmentation\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history = model.fit(x_train, y_train,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[save_best_model])\n",
        "\n",
        "  # train with data augmentation\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_validate, y_validate),\n",
        "                          callbacks=[save_best_model])\n",
        "    \n",
        "  # Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "  saved_model = load_model('best_model.h5')\n",
        "  scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  cnn_55_train = history.history['accuracy']\n",
        "  cnn_55_test = history.history['val_accuracy']\n",
        "  return cnn_55_train, cnn_55_test, scores[1]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJZNsFWK6yF-",
        "outputId": "101221b2-5537-4ecc-ca60-38f49ef26991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 100\n",
        "cnn_33_train_acc, cnn_33_test_acc, cnn_33_best = cnn(x_train, y_train, x_test, y_test)\n",
        "cnn_55_train_acc, cnn_55_test_acc, cnn_55_best = cnn_5x5(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not using data augmentation.\n",
            "Epoch 1/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 1.8302 - accuracy: 0.3308\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.43750, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8290 - accuracy: 0.3312 - val_loss: 1.5564 - val_accuracy: 0.4375\n",
            "Epoch 2/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.4927 - accuracy: 0.4616\n",
            "Epoch 00002: val_accuracy improved from 0.43750 to 0.52140, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4924 - accuracy: 0.4618 - val_loss: 1.3510 - val_accuracy: 0.5214\n",
            "Epoch 3/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.3451 - accuracy: 0.5193\n",
            "Epoch 00003: val_accuracy improved from 0.52140 to 0.56550, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3450 - accuracy: 0.5194 - val_loss: 1.2413 - val_accuracy: 0.5655\n",
            "Epoch 4/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.2442 - accuracy: 0.5583\n",
            "Epoch 00004: val_accuracy improved from 0.56550 to 0.59410, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2440 - accuracy: 0.5585 - val_loss: 1.1638 - val_accuracy: 0.5941\n",
            "Epoch 5/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.1682 - accuracy: 0.5854\n",
            "Epoch 00005: val_accuracy improved from 0.59410 to 0.60780, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1684 - accuracy: 0.5852 - val_loss: 1.1112 - val_accuracy: 0.6078\n",
            "Epoch 6/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 1.1049 - accuracy: 0.6090\n",
            "Epoch 00006: val_accuracy improved from 0.60780 to 0.64090, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1044 - accuracy: 0.6093 - val_loss: 1.0201 - val_accuracy: 0.6409\n",
            "Epoch 7/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 1.0481 - accuracy: 0.6341\n",
            "Epoch 00007: val_accuracy improved from 0.64090 to 0.65560, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0484 - accuracy: 0.6341 - val_loss: 0.9829 - val_accuracy: 0.6556\n",
            "Epoch 8/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9994 - accuracy: 0.6495\n",
            "Epoch 00008: val_accuracy improved from 0.65560 to 0.66860, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9998 - accuracy: 0.6494 - val_loss: 0.9432 - val_accuracy: 0.6686\n",
            "Epoch 9/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.9574 - accuracy: 0.6629\n",
            "Epoch 00009: val_accuracy improved from 0.66860 to 0.68130, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9581 - accuracy: 0.6627 - val_loss: 0.9090 - val_accuracy: 0.6813\n",
            "Epoch 10/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.9215 - accuracy: 0.6795\n",
            "Epoch 00010: val_accuracy improved from 0.68130 to 0.68940, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9218 - accuracy: 0.6794 - val_loss: 0.8988 - val_accuracy: 0.6894\n",
            "Epoch 11/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.8903 - accuracy: 0.6881\n",
            "Epoch 00011: val_accuracy improved from 0.68940 to 0.70460, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8906 - accuracy: 0.6880 - val_loss: 0.8470 - val_accuracy: 0.7046\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8671 - accuracy: 0.6995\n",
            "Epoch 00012: val_accuracy improved from 0.70460 to 0.71350, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8671 - accuracy: 0.6995 - val_loss: 0.8349 - val_accuracy: 0.7135\n",
            "Epoch 13/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.8418 - accuracy: 0.7107\n",
            "Epoch 00013: val_accuracy did not improve from 0.71350\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8417 - accuracy: 0.7107 - val_loss: 0.8580 - val_accuracy: 0.7053\n",
            "Epoch 14/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.8136 - accuracy: 0.7185\n",
            "Epoch 00014: val_accuracy improved from 0.71350 to 0.72250, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8136 - accuracy: 0.7186 - val_loss: 0.7912 - val_accuracy: 0.7225\n",
            "Epoch 15/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.8005 - accuracy: 0.7216\n",
            "Epoch 00015: val_accuracy improved from 0.72250 to 0.72460, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8011 - accuracy: 0.7212 - val_loss: 0.8022 - val_accuracy: 0.7246\n",
            "Epoch 16/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.7825 - accuracy: 0.7304\n",
            "Epoch 00016: val_accuracy improved from 0.72460 to 0.73090, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7826 - accuracy: 0.7303 - val_loss: 0.7803 - val_accuracy: 0.7309\n",
            "Epoch 17/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7653 - accuracy: 0.7352\n",
            "Epoch 00017: val_accuracy did not improve from 0.73090\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7662 - accuracy: 0.7350 - val_loss: 0.7835 - val_accuracy: 0.7285\n",
            "Epoch 18/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7546 - accuracy: 0.7400\n",
            "Epoch 00018: val_accuracy did not improve from 0.73090\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7550 - accuracy: 0.7401 - val_loss: 0.8010 - val_accuracy: 0.7258\n",
            "Epoch 19/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.7473 - accuracy: 0.7437\n",
            "Epoch 00019: val_accuracy improved from 0.73090 to 0.73910, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7474 - accuracy: 0.7436 - val_loss: 0.7563 - val_accuracy: 0.7391\n",
            "Epoch 20/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.7365 - accuracy: 0.7471\n",
            "Epoch 00020: val_accuracy improved from 0.73910 to 0.75110, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7366 - accuracy: 0.7472 - val_loss: 0.7333 - val_accuracy: 0.7511\n",
            "Epoch 21/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.7252 - accuracy: 0.7509\n",
            "Epoch 00021: val_accuracy did not improve from 0.75110\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7252 - accuracy: 0.7510 - val_loss: 0.7482 - val_accuracy: 0.7468\n",
            "Epoch 22/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.7135 - accuracy: 0.7568\n",
            "Epoch 00022: val_accuracy improved from 0.75110 to 0.75180, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7138 - accuracy: 0.7566 - val_loss: 0.7347 - val_accuracy: 0.7518\n",
            "Epoch 23/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.7081 - accuracy: 0.7590\n",
            "Epoch 00023: val_accuracy did not improve from 0.75180\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7081 - accuracy: 0.7590 - val_loss: 0.7344 - val_accuracy: 0.7513\n",
            "Epoch 24/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.7060 - accuracy: 0.7620\n",
            "Epoch 00024: val_accuracy improved from 0.75180 to 0.76070, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7063 - accuracy: 0.7618 - val_loss: 0.7111 - val_accuracy: 0.7607\n",
            "Epoch 25/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.7014 - accuracy: 0.7619\n",
            "Epoch 00025: val_accuracy did not improve from 0.76070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7021 - accuracy: 0.7618 - val_loss: 0.7432 - val_accuracy: 0.7517\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.7649\n",
            "Epoch 00026: val_accuracy improved from 0.76070 to 0.76230, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6921 - accuracy: 0.7649 - val_loss: 0.7162 - val_accuracy: 0.7623\n",
            "Epoch 27/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.7696\n",
            "Epoch 00027: val_accuracy improved from 0.76230 to 0.76450, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6829 - accuracy: 0.7695 - val_loss: 0.7256 - val_accuracy: 0.7645\n",
            "Epoch 28/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.7726\n",
            "Epoch 00028: val_accuracy improved from 0.76450 to 0.76570, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6763 - accuracy: 0.7728 - val_loss: 0.7212 - val_accuracy: 0.7657\n",
            "Epoch 29/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.7742\n",
            "Epoch 00029: val_accuracy did not improve from 0.76570\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6733 - accuracy: 0.7742 - val_loss: 0.7206 - val_accuracy: 0.7608\n",
            "Epoch 30/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6674 - accuracy: 0.7752\n",
            "Epoch 00030: val_accuracy did not improve from 0.76570\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6671 - accuracy: 0.7753 - val_loss: 0.7181 - val_accuracy: 0.7634\n",
            "Epoch 31/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6660 - accuracy: 0.7767\n",
            "Epoch 00031: val_accuracy improved from 0.76570 to 0.76860, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6660 - accuracy: 0.7767 - val_loss: 0.6995 - val_accuracy: 0.7686\n",
            "Epoch 32/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6594 - accuracy: 0.7803\n",
            "Epoch 00032: val_accuracy did not improve from 0.76860\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6594 - accuracy: 0.7802 - val_loss: 0.7436 - val_accuracy: 0.7538\n",
            "Epoch 33/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6571 - accuracy: 0.7806\n",
            "Epoch 00033: val_accuracy did not improve from 0.76860\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6575 - accuracy: 0.7804 - val_loss: 0.7308 - val_accuracy: 0.7646\n",
            "Epoch 34/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.6508 - accuracy: 0.7829\n",
            "Epoch 00034: val_accuracy improved from 0.76860 to 0.76920, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6517 - accuracy: 0.7825 - val_loss: 0.7796 - val_accuracy: 0.7692\n",
            "Epoch 35/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.7822\n",
            "Epoch 00035: val_accuracy did not improve from 0.76920\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6517 - accuracy: 0.7821 - val_loss: 0.7100 - val_accuracy: 0.7680\n",
            "Epoch 36/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6438 - accuracy: 0.7848\n",
            "Epoch 00036: val_accuracy improved from 0.76920 to 0.76960, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6435 - accuracy: 0.7848 - val_loss: 0.7129 - val_accuracy: 0.7696\n",
            "Epoch 37/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6411 - accuracy: 0.7871\n",
            "Epoch 00037: val_accuracy improved from 0.76960 to 0.77460, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6410 - accuracy: 0.7871 - val_loss: 0.7080 - val_accuracy: 0.7746\n",
            "Epoch 38/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6414 - accuracy: 0.7854\n",
            "Epoch 00038: val_accuracy did not improve from 0.77460\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6420 - accuracy: 0.7853 - val_loss: 0.8355 - val_accuracy: 0.7633\n",
            "Epoch 39/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6363 - accuracy: 0.7904\n",
            "Epoch 00039: val_accuracy did not improve from 0.77460\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6366 - accuracy: 0.7903 - val_loss: 0.7090 - val_accuracy: 0.7708\n",
            "Epoch 40/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6416 - accuracy: 0.7891\n",
            "Epoch 00040: val_accuracy did not improve from 0.77460\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6412 - accuracy: 0.7893 - val_loss: 0.7121 - val_accuracy: 0.7716\n",
            "Epoch 41/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6329 - accuracy: 0.7886\n",
            "Epoch 00041: val_accuracy did not improve from 0.77460\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6325 - accuracy: 0.7887 - val_loss: 0.6993 - val_accuracy: 0.7715\n",
            "Epoch 42/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6354 - accuracy: 0.7911\n",
            "Epoch 00042: val_accuracy improved from 0.77460 to 0.78070, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6362 - accuracy: 0.7908 - val_loss: 0.6922 - val_accuracy: 0.7807\n",
            "Epoch 43/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6330 - accuracy: 0.7890\n",
            "Epoch 00043: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6334 - accuracy: 0.7891 - val_loss: 0.7127 - val_accuracy: 0.7670\n",
            "Epoch 44/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6294 - accuracy: 0.7913\n",
            "Epoch 00044: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6292 - accuracy: 0.7914 - val_loss: 0.6836 - val_accuracy: 0.7771\n",
            "Epoch 45/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6299 - accuracy: 0.7928\n",
            "Epoch 00045: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6296 - accuracy: 0.7929 - val_loss: 0.6888 - val_accuracy: 0.7788\n",
            "Epoch 46/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6223 - accuracy: 0.7938\n",
            "Epoch 00046: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6225 - accuracy: 0.7936 - val_loss: 0.6884 - val_accuracy: 0.7805\n",
            "Epoch 47/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6277 - accuracy: 0.7927\n",
            "Epoch 00047: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6277 - accuracy: 0.7929 - val_loss: 0.7091 - val_accuracy: 0.7717\n",
            "Epoch 48/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6226 - accuracy: 0.7950\n",
            "Epoch 00048: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6225 - accuracy: 0.7950 - val_loss: 0.7112 - val_accuracy: 0.7709\n",
            "Epoch 49/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6227 - accuracy: 0.7960\n",
            "Epoch 00049: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6226 - accuracy: 0.7960 - val_loss: 0.6800 - val_accuracy: 0.7805\n",
            "Epoch 50/100\n",
            "1240/1250 [============================>.] - ETA: 0s - loss: 0.6193 - accuracy: 0.7977\n",
            "Epoch 00050: val_accuracy did not improve from 0.78070\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6195 - accuracy: 0.7976 - val_loss: 0.7493 - val_accuracy: 0.7685\n",
            "Epoch 51/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6210 - accuracy: 0.7952\n",
            "Epoch 00051: val_accuracy improved from 0.78070 to 0.78130, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6211 - accuracy: 0.7952 - val_loss: 0.7043 - val_accuracy: 0.7813\n",
            "Epoch 52/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6199 - accuracy: 0.7963\n",
            "Epoch 00052: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6201 - accuracy: 0.7962 - val_loss: 0.7161 - val_accuracy: 0.7789\n",
            "Epoch 53/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6164 - accuracy: 0.7995\n",
            "Epoch 00053: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6164 - accuracy: 0.7994 - val_loss: 0.7222 - val_accuracy: 0.7768\n",
            "Epoch 54/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6174 - accuracy: 0.7965\n",
            "Epoch 00054: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6171 - accuracy: 0.7966 - val_loss: 0.8021 - val_accuracy: 0.7737\n",
            "Epoch 55/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.7983\n",
            "Epoch 00055: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6111 - accuracy: 0.7982 - val_loss: 0.7223 - val_accuracy: 0.7762\n",
            "Epoch 56/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6116 - accuracy: 0.7976\n",
            "Epoch 00056: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6108 - accuracy: 0.7980 - val_loss: 0.8007 - val_accuracy: 0.7650\n",
            "Epoch 57/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6132 - accuracy: 0.8005\n",
            "Epoch 00057: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6133 - accuracy: 0.8005 - val_loss: 0.7320 - val_accuracy: 0.7795\n",
            "Epoch 58/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6151 - accuracy: 0.7994\n",
            "Epoch 00058: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6145 - accuracy: 0.7997 - val_loss: 0.6895 - val_accuracy: 0.7773\n",
            "Epoch 59/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6101 - accuracy: 0.7995\n",
            "Epoch 00059: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6100 - accuracy: 0.7995 - val_loss: 0.7014 - val_accuracy: 0.7719\n",
            "Epoch 60/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6147 - accuracy: 0.7973\n",
            "Epoch 00060: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6151 - accuracy: 0.7976 - val_loss: 0.7466 - val_accuracy: 0.7781\n",
            "Epoch 61/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.8028\n",
            "Epoch 00061: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6080 - accuracy: 0.8026 - val_loss: 0.7342 - val_accuracy: 0.7803\n",
            "Epoch 62/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.8022\n",
            "Epoch 00062: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6090 - accuracy: 0.8021 - val_loss: 0.7002 - val_accuracy: 0.7797\n",
            "Epoch 63/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6078 - accuracy: 0.8013\n",
            "Epoch 00063: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6076 - accuracy: 0.8013 - val_loss: 0.6984 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.7997\n",
            "Epoch 00064: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6062 - accuracy: 0.7997 - val_loss: 0.7192 - val_accuracy: 0.7811\n",
            "Epoch 65/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6100 - accuracy: 0.8021\n",
            "Epoch 00065: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6099 - accuracy: 0.8021 - val_loss: 0.7254 - val_accuracy: 0.7734\n",
            "Epoch 66/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6080 - accuracy: 0.8030\n",
            "Epoch 00066: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6081 - accuracy: 0.8030 - val_loss: 0.7495 - val_accuracy: 0.7767\n",
            "Epoch 67/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.8017\n",
            "Epoch 00067: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6104 - accuracy: 0.8015 - val_loss: 0.7752 - val_accuracy: 0.7650\n",
            "Epoch 68/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6053 - accuracy: 0.8015\n",
            "Epoch 00068: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6053 - accuracy: 0.8014 - val_loss: 0.7254 - val_accuracy: 0.7771\n",
            "Epoch 69/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6073 - accuracy: 0.8036\n",
            "Epoch 00069: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6079 - accuracy: 0.8035 - val_loss: 0.7711 - val_accuracy: 0.7704\n",
            "Epoch 70/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.5994 - accuracy: 0.8065\n",
            "Epoch 00070: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5996 - accuracy: 0.8065 - val_loss: 0.8357 - val_accuracy: 0.7784\n",
            "Epoch 71/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.6100 - accuracy: 0.8018\n",
            "Epoch 00071: val_accuracy did not improve from 0.78130\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6102 - accuracy: 0.8017 - val_loss: 0.7254 - val_accuracy: 0.7757\n",
            "Epoch 72/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.8041\n",
            "Epoch 00072: val_accuracy improved from 0.78130 to 0.78530, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6062 - accuracy: 0.8042 - val_loss: 0.6922 - val_accuracy: 0.7853\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.8055\n",
            "Epoch 00073: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6076 - accuracy: 0.8055 - val_loss: 0.7582 - val_accuracy: 0.7712\n",
            "Epoch 74/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6085 - accuracy: 0.8022\n",
            "Epoch 00074: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6086 - accuracy: 0.8021 - val_loss: 0.7742 - val_accuracy: 0.7733\n",
            "Epoch 75/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.8055\n",
            "Epoch 00075: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6094 - accuracy: 0.8056 - val_loss: 0.6943 - val_accuracy: 0.7831\n",
            "Epoch 76/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6075 - accuracy: 0.8020\n",
            "Epoch 00076: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6076 - accuracy: 0.8020 - val_loss: 0.7263 - val_accuracy: 0.7783\n",
            "Epoch 77/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6130 - accuracy: 0.8020\n",
            "Epoch 00077: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6123 - accuracy: 0.8023 - val_loss: 0.7107 - val_accuracy: 0.7796\n",
            "Epoch 78/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6022 - accuracy: 0.8054\n",
            "Epoch 00078: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6022 - accuracy: 0.8053 - val_loss: 0.7523 - val_accuracy: 0.7733\n",
            "Epoch 79/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.6008 - accuracy: 0.8056\n",
            "Epoch 00079: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6010 - accuracy: 0.8055 - val_loss: 0.7217 - val_accuracy: 0.7780\n",
            "Epoch 80/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.8049\n",
            "Epoch 00080: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6053 - accuracy: 0.8048 - val_loss: 0.7326 - val_accuracy: 0.7767\n",
            "Epoch 81/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.8035\n",
            "Epoch 00081: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6052 - accuracy: 0.8036 - val_loss: 0.7403 - val_accuracy: 0.7815\n",
            "Epoch 82/100\n",
            "1241/1250 [============================>.] - ETA: 0s - loss: 0.6085 - accuracy: 0.8024\n",
            "Epoch 00082: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6084 - accuracy: 0.8023 - val_loss: 1.0155 - val_accuracy: 0.7342\n",
            "Epoch 83/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6109 - accuracy: 0.8021\n",
            "Epoch 00083: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6106 - accuracy: 0.8022 - val_loss: 0.7011 - val_accuracy: 0.7832\n",
            "Epoch 84/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6045 - accuracy: 0.8056\n",
            "Epoch 00084: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6044 - accuracy: 0.8055 - val_loss: 0.7223 - val_accuracy: 0.7682\n",
            "Epoch 85/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6092 - accuracy: 0.8029\n",
            "Epoch 00085: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6093 - accuracy: 0.8028 - val_loss: 0.7543 - val_accuracy: 0.7596\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.8045\n",
            "Epoch 00086: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6080 - accuracy: 0.8045 - val_loss: 0.7140 - val_accuracy: 0.7732\n",
            "Epoch 87/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6076 - accuracy: 0.8010\n",
            "Epoch 00087: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6077 - accuracy: 0.8011 - val_loss: 0.7386 - val_accuracy: 0.7701\n",
            "Epoch 88/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.6088 - accuracy: 0.8039\n",
            "Epoch 00088: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6090 - accuracy: 0.8039 - val_loss: 0.8254 - val_accuracy: 0.7649\n",
            "Epoch 89/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6042 - accuracy: 0.8037\n",
            "Epoch 00089: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6034 - accuracy: 0.8038 - val_loss: 0.7298 - val_accuracy: 0.7761\n",
            "Epoch 90/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6130 - accuracy: 0.8008\n",
            "Epoch 00090: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6134 - accuracy: 0.8007 - val_loss: 0.8078 - val_accuracy: 0.7685\n",
            "Epoch 91/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.8030\n",
            "Epoch 00091: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6092 - accuracy: 0.8032 - val_loss: 0.7624 - val_accuracy: 0.7599\n",
            "Epoch 92/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.8039\n",
            "Epoch 00092: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6076 - accuracy: 0.8038 - val_loss: 0.7795 - val_accuracy: 0.7636\n",
            "Epoch 93/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6124 - accuracy: 0.8035\n",
            "Epoch 00093: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6124 - accuracy: 0.8035 - val_loss: 0.7192 - val_accuracy: 0.7753\n",
            "Epoch 94/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.6064 - accuracy: 0.8024\n",
            "Epoch 00094: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6066 - accuracy: 0.8023 - val_loss: 0.7943 - val_accuracy: 0.7723\n",
            "Epoch 95/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6082 - accuracy: 0.8004\n",
            "Epoch 00095: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6078 - accuracy: 0.8005 - val_loss: 0.7778 - val_accuracy: 0.7637\n",
            "Epoch 96/100\n",
            "1242/1250 [============================>.] - ETA: 0s - loss: 0.6139 - accuracy: 0.8014\n",
            "Epoch 00096: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6135 - accuracy: 0.8015 - val_loss: 0.7264 - val_accuracy: 0.7744\n",
            "Epoch 97/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.8045\n",
            "Epoch 00097: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6092 - accuracy: 0.8045 - val_loss: 0.9749 - val_accuracy: 0.7404\n",
            "Epoch 98/100\n",
            "1243/1250 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.8043\n",
            "Epoch 00098: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6102 - accuracy: 0.8044 - val_loss: 0.8567 - val_accuracy: 0.7412\n",
            "Epoch 99/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6104 - accuracy: 0.8027\n",
            "Epoch 00099: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6100 - accuracy: 0.8029 - val_loss: 0.7646 - val_accuracy: 0.7723\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.8039\n",
            "Epoch 00100: val_accuracy did not improve from 0.78530\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6095 - accuracy: 0.8039 - val_loss: 0.9115 - val_accuracy: 0.7572\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.7787\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_110 (Conv2D)          (None, 32, 32, 32)        2432      \n",
            "_________________________________________________________________\n",
            "activation_166 (Activation)  (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 32, 32, 32)        25632     \n",
            "_________________________________________________________________\n",
            "activation_167 (Activation)  (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_108 (Dropout)        (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 16, 16, 64)        51264     \n",
            "_________________________________________________________________\n",
            "activation_168 (Activation)  (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 16, 16, 64)        102464    \n",
            "_________________________________________________________________\n",
            "activation_169 (Activation)  (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_109 (Dropout)        (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_46 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_170 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_110 (Dropout)        (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_171 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,284,586\n",
            "Trainable params: 2,284,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Not using data augmentation.\n",
            "Epoch 1/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 1.7927 - accuracy: 0.3434\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.45840, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 1.7923 - accuracy: 0.3437 - val_loss: 1.4908 - val_accuracy: 0.4584\n",
            "Epoch 2/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 1.4551 - accuracy: 0.4738\n",
            "Epoch 00002: val_accuracy improved from 0.45840 to 0.51870, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4542 - accuracy: 0.4739 - val_loss: 1.3464 - val_accuracy: 0.5187\n",
            "Epoch 3/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 1.2965 - accuracy: 0.5364\n",
            "Epoch 00003: val_accuracy improved from 0.51870 to 0.57820, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2961 - accuracy: 0.5367 - val_loss: 1.1936 - val_accuracy: 0.5782\n",
            "Epoch 4/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.1718 - accuracy: 0.5838\n",
            "Epoch 00004: val_accuracy improved from 0.57820 to 0.62970, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1717 - accuracy: 0.5839 - val_loss: 1.0461 - val_accuracy: 0.6297\n",
            "Epoch 5/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 1.0753 - accuracy: 0.6196\n",
            "Epoch 00005: val_accuracy did not improve from 0.62970\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0753 - accuracy: 0.6195 - val_loss: 1.1110 - val_accuracy: 0.6177\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.6440\n",
            "Epoch 00006: val_accuracy improved from 0.62970 to 0.67310, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0083 - accuracy: 0.6440 - val_loss: 0.9321 - val_accuracy: 0.6731\n",
            "Epoch 7/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.9465 - accuracy: 0.6662\n",
            "Epoch 00007: val_accuracy improved from 0.67310 to 0.68940, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9462 - accuracy: 0.6664 - val_loss: 0.8931 - val_accuracy: 0.6894\n",
            "Epoch 8/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.8961 - accuracy: 0.6872\n",
            "Epoch 00008: val_accuracy improved from 0.68940 to 0.69650, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8961 - accuracy: 0.6872 - val_loss: 0.8673 - val_accuracy: 0.6965\n",
            "Epoch 9/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8557 - accuracy: 0.7023\n",
            "Epoch 00009: val_accuracy improved from 0.69650 to 0.71630, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8559 - accuracy: 0.7023 - val_loss: 0.8181 - val_accuracy: 0.7163\n",
            "Epoch 10/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.8153 - accuracy: 0.7159\n",
            "Epoch 00010: val_accuracy improved from 0.71630 to 0.72560, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8151 - accuracy: 0.7159 - val_loss: 0.8055 - val_accuracy: 0.7256\n",
            "Epoch 11/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.7847 - accuracy: 0.7290\n",
            "Epoch 00011: val_accuracy improved from 0.72560 to 0.73600, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7845 - accuracy: 0.7290 - val_loss: 0.7645 - val_accuracy: 0.7360\n",
            "Epoch 12/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.7546 - accuracy: 0.7392\n",
            "Epoch 00012: val_accuracy did not improve from 0.73600\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7544 - accuracy: 0.7392 - val_loss: 0.8155 - val_accuracy: 0.7212\n",
            "Epoch 13/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.7308 - accuracy: 0.7432\n",
            "Epoch 00013: val_accuracy improved from 0.73600 to 0.74610, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7302 - accuracy: 0.7435 - val_loss: 0.7446 - val_accuracy: 0.7461\n",
            "Epoch 14/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.7122 - accuracy: 0.7519\n",
            "Epoch 00014: val_accuracy improved from 0.74610 to 0.74790, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.7125 - accuracy: 0.7519 - val_loss: 0.7290 - val_accuracy: 0.7479\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.7618\n",
            "Epoch 00015: val_accuracy improved from 0.74790 to 0.75640, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6914 - accuracy: 0.7618 - val_loss: 0.7076 - val_accuracy: 0.7564\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.7681\n",
            "Epoch 00016: val_accuracy improved from 0.75640 to 0.76040, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.6712 - accuracy: 0.7681 - val_loss: 0.7031 - val_accuracy: 0.7604\n",
            "Epoch 17/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6515 - accuracy: 0.7760\n",
            "Epoch 00017: val_accuracy improved from 0.76040 to 0.76270, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.6522 - accuracy: 0.7759 - val_loss: 0.7114 - val_accuracy: 0.7627\n",
            "Epoch 18/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6392 - accuracy: 0.7818\n",
            "Epoch 00018: val_accuracy did not improve from 0.76270\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.6389 - accuracy: 0.7819 - val_loss: 0.7135 - val_accuracy: 0.7615\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.7854\n",
            "Epoch 00019: val_accuracy did not improve from 0.76270\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6246 - accuracy: 0.7854 - val_loss: 0.7044 - val_accuracy: 0.7622\n",
            "Epoch 20/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.7905\n",
            "Epoch 00020: val_accuracy improved from 0.76270 to 0.77000, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.6126 - accuracy: 0.7906 - val_loss: 0.6825 - val_accuracy: 0.7700\n",
            "Epoch 21/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.6006 - accuracy: 0.7925\n",
            "Epoch 00021: val_accuracy improved from 0.77000 to 0.77610, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6007 - accuracy: 0.7924 - val_loss: 0.6777 - val_accuracy: 0.7761\n",
            "Epoch 22/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.5886 - accuracy: 0.7997\n",
            "Epoch 00022: val_accuracy did not improve from 0.77610\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5886 - accuracy: 0.7996 - val_loss: 0.6906 - val_accuracy: 0.7682\n",
            "Epoch 23/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.5807 - accuracy: 0.8028\n",
            "Epoch 00023: val_accuracy did not improve from 0.77610\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5804 - accuracy: 0.8029 - val_loss: 0.7286 - val_accuracy: 0.7654\n",
            "Epoch 24/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.5717 - accuracy: 0.8038\n",
            "Epoch 00024: val_accuracy improved from 0.77610 to 0.77630, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5712 - accuracy: 0.8040 - val_loss: 0.6953 - val_accuracy: 0.7763\n",
            "Epoch 25/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5679 - accuracy: 0.8070\n",
            "Epoch 00025: val_accuracy improved from 0.77630 to 0.77640, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5679 - accuracy: 0.8070 - val_loss: 0.6822 - val_accuracy: 0.7764\n",
            "Epoch 26/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.5553 - accuracy: 0.8108\n",
            "Epoch 00026: val_accuracy improved from 0.77640 to 0.78500, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5553 - accuracy: 0.8108 - val_loss: 0.6618 - val_accuracy: 0.7850\n",
            "Epoch 27/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.5487 - accuracy: 0.8139\n",
            "Epoch 00027: val_accuracy did not improve from 0.78500\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5488 - accuracy: 0.8138 - val_loss: 0.6696 - val_accuracy: 0.7793\n",
            "Epoch 28/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.8171\n",
            "Epoch 00028: val_accuracy did not improve from 0.78500\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5400 - accuracy: 0.8171 - val_loss: 0.6841 - val_accuracy: 0.7778\n",
            "Epoch 29/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.8182\n",
            "Epoch 00029: val_accuracy improved from 0.78500 to 0.78570, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5324 - accuracy: 0.8183 - val_loss: 0.6755 - val_accuracy: 0.7857\n",
            "Epoch 30/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.5236 - accuracy: 0.8218\n",
            "Epoch 00030: val_accuracy did not improve from 0.78570\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5238 - accuracy: 0.8217 - val_loss: 0.6853 - val_accuracy: 0.7771\n",
            "Epoch 31/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.5232 - accuracy: 0.8234\n",
            "Epoch 00031: val_accuracy improved from 0.78570 to 0.78630, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5235 - accuracy: 0.8233 - val_loss: 0.6542 - val_accuracy: 0.7863\n",
            "Epoch 32/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.5161 - accuracy: 0.8257\n",
            "Epoch 00032: val_accuracy did not improve from 0.78630\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5167 - accuracy: 0.8254 - val_loss: 0.6756 - val_accuracy: 0.7792\n",
            "Epoch 33/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.5126 - accuracy: 0.8271\n",
            "Epoch 00033: val_accuracy improved from 0.78630 to 0.78710, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5130 - accuracy: 0.8270 - val_loss: 0.6614 - val_accuracy: 0.7871\n",
            "Epoch 34/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.8288\n",
            "Epoch 00034: val_accuracy did not improve from 0.78710\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5056 - accuracy: 0.8289 - val_loss: 0.7057 - val_accuracy: 0.7831\n",
            "Epoch 35/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.8303\n",
            "Epoch 00035: val_accuracy did not improve from 0.78710\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.5032 - accuracy: 0.8301 - val_loss: 0.6679 - val_accuracy: 0.7865\n",
            "Epoch 36/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4916 - accuracy: 0.8373\n",
            "Epoch 00036: val_accuracy did not improve from 0.78710\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4920 - accuracy: 0.8372 - val_loss: 0.6592 - val_accuracy: 0.7868\n",
            "Epoch 37/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8316\n",
            "Epoch 00037: val_accuracy improved from 0.78710 to 0.79110, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4948 - accuracy: 0.8318 - val_loss: 0.6689 - val_accuracy: 0.7911\n",
            "Epoch 38/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.8349\n",
            "Epoch 00038: val_accuracy did not improve from 0.79110\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4901 - accuracy: 0.8349 - val_loss: 0.7280 - val_accuracy: 0.7836\n",
            "Epoch 39/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.4830 - accuracy: 0.8372\n",
            "Epoch 00039: val_accuracy did not improve from 0.79110\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4830 - accuracy: 0.8373 - val_loss: 0.6749 - val_accuracy: 0.7905\n",
            "Epoch 40/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4814 - accuracy: 0.8404\n",
            "Epoch 00040: val_accuracy improved from 0.79110 to 0.79190, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4815 - accuracy: 0.8404 - val_loss: 0.6690 - val_accuracy: 0.7919\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.8421\n",
            "Epoch 00041: val_accuracy improved from 0.79190 to 0.79330, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4767 - accuracy: 0.8421 - val_loss: 0.6640 - val_accuracy: 0.7933\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.8439\n",
            "Epoch 00042: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4702 - accuracy: 0.8439 - val_loss: 0.6825 - val_accuracy: 0.7912\n",
            "Epoch 43/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4724 - accuracy: 0.8423\n",
            "Epoch 00043: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4722 - accuracy: 0.8423 - val_loss: 0.7590 - val_accuracy: 0.7835\n",
            "Epoch 44/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4747 - accuracy: 0.8433\n",
            "Epoch 00044: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4745 - accuracy: 0.8433 - val_loss: 0.7075 - val_accuracy: 0.7878\n",
            "Epoch 45/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.8474\n",
            "Epoch 00045: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4591 - accuracy: 0.8473 - val_loss: 0.6857 - val_accuracy: 0.7845\n",
            "Epoch 46/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.8466\n",
            "Epoch 00046: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4613 - accuracy: 0.8467 - val_loss: 0.6761 - val_accuracy: 0.7883\n",
            "Epoch 47/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.8467\n",
            "Epoch 00047: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4656 - accuracy: 0.8468 - val_loss: 0.7007 - val_accuracy: 0.7905\n",
            "Epoch 48/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4570 - accuracy: 0.8486\n",
            "Epoch 00048: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4570 - accuracy: 0.8486 - val_loss: 0.7312 - val_accuracy: 0.7928\n",
            "Epoch 49/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4562 - accuracy: 0.8509\n",
            "Epoch 00049: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4563 - accuracy: 0.8508 - val_loss: 0.6961 - val_accuracy: 0.7848\n",
            "Epoch 50/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.4558 - accuracy: 0.8489\n",
            "Epoch 00050: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4560 - accuracy: 0.8490 - val_loss: 0.6835 - val_accuracy: 0.7916\n",
            "Epoch 51/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.8511\n",
            "Epoch 00051: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4520 - accuracy: 0.8511 - val_loss: 0.6763 - val_accuracy: 0.7926\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4498 - accuracy: 0.8531\n",
            "Epoch 00052: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4498 - accuracy: 0.8531 - val_loss: 0.6917 - val_accuracy: 0.7870\n",
            "Epoch 53/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4592 - accuracy: 0.8485\n",
            "Epoch 00053: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4591 - accuracy: 0.8486 - val_loss: 0.6723 - val_accuracy: 0.7889\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8496\n",
            "Epoch 00054: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4546 - accuracy: 0.8496 - val_loss: 0.6806 - val_accuracy: 0.7903\n",
            "Epoch 55/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.8530\n",
            "Epoch 00055: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4555 - accuracy: 0.8530 - val_loss: 0.7020 - val_accuracy: 0.7838\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.8519\n",
            "Epoch 00056: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4512 - accuracy: 0.8519 - val_loss: 0.7802 - val_accuracy: 0.7707\n",
            "Epoch 57/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.8524\n",
            "Epoch 00057: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4551 - accuracy: 0.8525 - val_loss: 0.6970 - val_accuracy: 0.7863\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.8529\n",
            "Epoch 00058: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4548 - accuracy: 0.8529 - val_loss: 0.7035 - val_accuracy: 0.7850\n",
            "Epoch 59/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4405 - accuracy: 0.8546\n",
            "Epoch 00059: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4401 - accuracy: 0.8548 - val_loss: 0.8055 - val_accuracy: 0.7912\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8540\n",
            "Epoch 00060: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4451 - accuracy: 0.8540 - val_loss: 0.7424 - val_accuracy: 0.7730\n",
            "Epoch 61/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4418 - accuracy: 0.8540\n",
            "Epoch 00061: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4416 - accuracy: 0.8541 - val_loss: 0.6974 - val_accuracy: 0.7928\n",
            "Epoch 62/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4458 - accuracy: 0.8552\n",
            "Epoch 00062: val_accuracy did not improve from 0.79330\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4458 - accuracy: 0.8553 - val_loss: 0.7158 - val_accuracy: 0.7893\n",
            "Epoch 63/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.8557\n",
            "Epoch 00063: val_accuracy improved from 0.79330 to 0.79600, saving model to best_model.h5\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4416 - accuracy: 0.8557 - val_loss: 0.7328 - val_accuracy: 0.7960\n",
            "Epoch 64/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4386 - accuracy: 0.8576\n",
            "Epoch 00064: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4385 - accuracy: 0.8577 - val_loss: 0.7367 - val_accuracy: 0.7876\n",
            "Epoch 65/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4451 - accuracy: 0.8573\n",
            "Epoch 00065: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4455 - accuracy: 0.8572 - val_loss: 0.7352 - val_accuracy: 0.7838\n",
            "Epoch 66/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4405 - accuracy: 0.8560\n",
            "Epoch 00066: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4406 - accuracy: 0.8559 - val_loss: 0.7779 - val_accuracy: 0.7757\n",
            "Epoch 67/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.8552\n",
            "Epoch 00067: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4445 - accuracy: 0.8551 - val_loss: 0.7198 - val_accuracy: 0.7757\n",
            "Epoch 68/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4409 - accuracy: 0.8570\n",
            "Epoch 00068: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4416 - accuracy: 0.8568 - val_loss: 0.6957 - val_accuracy: 0.7878\n",
            "Epoch 69/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.4470 - accuracy: 0.8557\n",
            "Epoch 00069: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4472 - accuracy: 0.8556 - val_loss: 0.7690 - val_accuracy: 0.7841\n",
            "Epoch 70/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4498 - accuracy: 0.8555\n",
            "Epoch 00070: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4500 - accuracy: 0.8554 - val_loss: 0.7227 - val_accuracy: 0.7864\n",
            "Epoch 71/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.4477 - accuracy: 0.8561\n",
            "Epoch 00071: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4479 - accuracy: 0.8559 - val_loss: 0.7425 - val_accuracy: 0.7833\n",
            "Epoch 72/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4464 - accuracy: 0.8563\n",
            "Epoch 00072: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4461 - accuracy: 0.8564 - val_loss: 0.7520 - val_accuracy: 0.7939\n",
            "Epoch 73/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.8575\n",
            "Epoch 00073: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4448 - accuracy: 0.8574 - val_loss: 0.7429 - val_accuracy: 0.7831\n",
            "Epoch 74/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4488 - accuracy: 0.8565\n",
            "Epoch 00074: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4489 - accuracy: 0.8566 - val_loss: 0.7281 - val_accuracy: 0.7834\n",
            "Epoch 75/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4495 - accuracy: 0.8566\n",
            "Epoch 00075: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4491 - accuracy: 0.8568 - val_loss: 0.7335 - val_accuracy: 0.7957\n",
            "Epoch 76/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4462 - accuracy: 0.8564\n",
            "Epoch 00076: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4460 - accuracy: 0.8565 - val_loss: 0.6999 - val_accuracy: 0.7898\n",
            "Epoch 77/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.8581\n",
            "Epoch 00077: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4462 - accuracy: 0.8583 - val_loss: 0.8297 - val_accuracy: 0.7915\n",
            "Epoch 78/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.4500 - accuracy: 0.8571\n",
            "Epoch 00078: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4503 - accuracy: 0.8569 - val_loss: 0.7304 - val_accuracy: 0.7885\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.8552\n",
            "Epoch 00079: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4543 - accuracy: 0.8552 - val_loss: 0.7258 - val_accuracy: 0.7878\n",
            "Epoch 80/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.8552\n",
            "Epoch 00080: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4517 - accuracy: 0.8553 - val_loss: 0.7321 - val_accuracy: 0.7865\n",
            "Epoch 81/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8559\n",
            "Epoch 00081: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4505 - accuracy: 0.8559 - val_loss: 0.8549 - val_accuracy: 0.7767\n",
            "Epoch 82/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.4542 - accuracy: 0.8554\n",
            "Epoch 00082: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4548 - accuracy: 0.8552 - val_loss: 0.7786 - val_accuracy: 0.7711\n",
            "Epoch 83/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4530 - accuracy: 0.8573\n",
            "Epoch 00083: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4530 - accuracy: 0.8573 - val_loss: 0.7643 - val_accuracy: 0.7719\n",
            "Epoch 84/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4538 - accuracy: 0.8539\n",
            "Epoch 00084: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4536 - accuracy: 0.8539 - val_loss: 0.7399 - val_accuracy: 0.7819\n",
            "Epoch 85/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4533 - accuracy: 0.8561\n",
            "Epoch 00085: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.4537 - accuracy: 0.8559 - val_loss: 0.7756 - val_accuracy: 0.7758\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.8568\n",
            "Epoch 00086: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4583 - accuracy: 0.8568 - val_loss: 0.7522 - val_accuracy: 0.7890\n",
            "Epoch 87/100\n",
            "1244/1250 [============================>.] - ETA: 0s - loss: 0.4528 - accuracy: 0.8567\n",
            "Epoch 00087: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4524 - accuracy: 0.8566 - val_loss: 0.6877 - val_accuracy: 0.7914\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.8571\n",
            "Epoch 00088: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4571 - accuracy: 0.8571 - val_loss: 0.7167 - val_accuracy: 0.7926\n",
            "Epoch 89/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4585 - accuracy: 0.8552\n",
            "Epoch 00089: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4585 - accuracy: 0.8552 - val_loss: 0.7686 - val_accuracy: 0.7738\n",
            "Epoch 90/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8546\n",
            "Epoch 00090: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4606 - accuracy: 0.8547 - val_loss: 0.7517 - val_accuracy: 0.7779\n",
            "Epoch 91/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.8568\n",
            "Epoch 00091: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4562 - accuracy: 0.8569 - val_loss: 0.7191 - val_accuracy: 0.7851\n",
            "Epoch 92/100\n",
            "1245/1250 [============================>.] - ETA: 0s - loss: 0.4611 - accuracy: 0.8548\n",
            "Epoch 00092: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4610 - accuracy: 0.8548 - val_loss: 0.7626 - val_accuracy: 0.7801\n",
            "Epoch 93/100\n",
            "1247/1250 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.8539\n",
            "Epoch 00093: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4646 - accuracy: 0.8540 - val_loss: 0.7380 - val_accuracy: 0.7902\n",
            "Epoch 94/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8566\n",
            "Epoch 00094: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4611 - accuracy: 0.8566 - val_loss: 0.7783 - val_accuracy: 0.7890\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.8542\n",
            "Epoch 00095: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4663 - accuracy: 0.8542 - val_loss: 0.7203 - val_accuracy: 0.7881\n",
            "Epoch 96/100\n",
            "1248/1250 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.8538\n",
            "Epoch 00096: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4684 - accuracy: 0.8539 - val_loss: 0.7459 - val_accuracy: 0.7813\n",
            "Epoch 97/100\n",
            "1246/1250 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8534\n",
            "Epoch 00097: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4642 - accuracy: 0.8534 - val_loss: 0.7348 - val_accuracy: 0.7844\n",
            "Epoch 98/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.8538\n",
            "Epoch 00098: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4708 - accuracy: 0.8539 - val_loss: 0.7319 - val_accuracy: 0.7844\n",
            "Epoch 99/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4748 - accuracy: 0.8493\n",
            "Epoch 00099: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4747 - accuracy: 0.8493 - val_loss: 0.7482 - val_accuracy: 0.7799\n",
            "Epoch 100/100\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.8534\n",
            "Epoch 00100: val_accuracy did not improve from 0.79600\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.4753 - accuracy: 0.8535 - val_loss: 0.7188 - val_accuracy: 0.7885\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7575 - accuracy: 0.7906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyPEvjuv6rFN",
        "outputId": "f68e8078-44c3-4ac2-a5aa-09e605c6b160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "plt.plot( cnn_33_train_acc )\n",
        "plt.plot( cnn_55_train_acc )\n",
        "\n",
        "plt.title('Train Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['5x5', '3x3'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot( cnn_33_test_acc )\n",
        "plt.plot( cnn_55_test_acc )\n",
        "\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['5x5', '3x3'], loc='upper left')\n",
        "plt.show()\n",
        "print('best validation accuracy of 3x3:', cnn_33_best)\n",
        "print('best validation accuracy of 5x5:', cnn_55_best)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best validation accuracy of 3x3: 0.7786999940872192\n",
            "best validation accuracy of 5x5: 0.7906000018119812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wd5l-8NYunw"
      },
      "source": [
        "For part 5, filter size of 3x3 performs better than 5x5 most time. Larger filer size helps to figue out bigger feature of the data. The 3x3 filter performs better means that for the data, smaller features fits better."
      ]
    }
  ]
}