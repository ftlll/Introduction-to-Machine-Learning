{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs480_fall20_asst3_generalized_linear_regression_skeleton.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFXZug066bJX"
      },
      "source": [
        "# Upload files in Google Colab\n",
        "If you are running this Jupyter Notebook on Google Colab, run this cell to upload the data files (train_inputs.csv, train_targets.csv, test_inputs.csv, test_targets.csv) in the colab virtual machine.  You will be prompted to select files that you would like to upload. \n",
        "\n",
        "If you are running this Jupyter Notebook on your computer, you do not need to run this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqBJV_Br4XeI"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZDpxE4jmFwA"
      },
      "source": [
        "# Import libraries \n",
        "Do not use any other Python library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_1d0BPfmacB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6keYhcgi7nbf"
      },
      "source": [
        "# Function: load_generalized_linear_regression_data\n",
        "\n",
        "This function loads the data for Generalized Linear Regression from a local drive into RAM\n",
        "\n",
        "Outputs:\n",
        "\n",
        "*   **train_inputs**: numpy array of N training data points x M features\n",
        "*   **train_targets**: numpy array of N training targets\n",
        "*   **test_inputs**: numpy array of N' test data points x M features\n",
        "*   **test_targets**: numpy array of N' test targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcG5U2lR7utt"
      },
      "source": [
        "def load_generalized_linear_regression_data():\n",
        "  test_inputs = np.genfromtxt('test_inputs.csv', delimiter=',')\n",
        "  test_targets = np.genfromtxt('test_targets.csv', delimiter=',')\n",
        "  train_inputs = np.genfromtxt('train_inputs.csv', delimiter=',')\n",
        "  train_targets = np.genfromtxt('train_targets.csv', delimiter=',')\n",
        "  return train_inputs, train_targets, test_inputs, test_targets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwLo3p4f8bTa"
      },
      "source": [
        "# Function: predict_generalized_linear_regression\n",
        "\n",
        "This function uses a vector of weights to make predictions for a set of inputs.\n",
        "\n",
        "Inputs:\n",
        "*   **inputs**: matrix of input data points for which we want to make a prediction (numpy array of N data points x M' features)\n",
        "*   **weights**: vector of weights (numpy array of M' weights)\n",
        "\n",
        "Output:\n",
        "*   **predicted_values**: vector of predicted values (numpy array of N floats)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX04_wClRqkV"
      },
      "source": [
        "def predict_generalized_linear_regression(inputs, weights):\n",
        "  \n",
        "  # dummy assignment until the function is filled in\n",
        "  predicted_values = np.zeros(inputs.shape[0])\n",
        "  return predicted_values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmfPN7K0RtQ5"
      },
      "source": [
        "# Function eval_generalized_linear_regression\n",
        "\n",
        "This function evaluates a set of predictions by computing the mean squared error with respect to the targets\n",
        "\n",
        "Inputs:\n",
        "*   **inputs**: matrix of input data points for which we will evaluate the predictions (numpy array of N data points x M' features)\n",
        "*   **weights**: vector of weights (numpy array of M' weights)\n",
        "*   **targets**: vector of targets associated with the inputs (numpy array of N targets)\n",
        "\n",
        "Output:\n",
        "*   **mean_squared_error**: mean squared error between the predicted values and the targets (scalar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC14LEsvTxbu"
      },
      "source": [
        "def eval_generalized_linear_regression(inputs, weights, targets):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  mean_squared_error = 0\n",
        "  return mean_squared_error"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMAzC5xXT0H-"
      },
      "source": [
        "# Function train_generalized_linear_regression\n",
        "\n",
        "This function optimizes a set of weights for generalized linear regression based on a training set\n",
        "\n",
        "Inputs:\n",
        "*   **train_inputs**: matrix of input training points (numpy array of N data points x M' features)\n",
        "*   **train_targets**: vector of targets associated with the inputs (numpy array of N targets)\n",
        "*   **lambda_hyperparam**: lambda hyperparameter used to adjust the importance of the regularizer (scalar)\n",
        "\n",
        "Output:\n",
        "*   **weights**: vector of weights that have been optimized (numpy array of M' weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DkzoT5QVy41"
      },
      "source": [
        "def train_generalized_linear_regression(train_inputs, train_targets, lambda_hyperparam):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  weights = np.zeros(train_inputs.shape[1])\n",
        "  return weights"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIRUQG_C18EF"
      },
      "source": [
        "# Function monomial_features\n",
        "\n",
        "This function computes monomial basis functions up to degree $d$: $\\{\\prod_i (x_i)^{n_i} | \\sum_i n_i \\le d\\}$.  A monomial of degree\n",
        "less than or equal to $d$ is a product of variables (e.g., $\\prod_i (x_i)^{n_i}$ where the sum of their exponents is less\n",
        "than or equal to d (i.e., $\\sum_i n_i \\le d$).\n",
        "\n",
        "Inputs:\n",
        "*   **max_degree**: maximum degree d for the monomial basis functions (integer)\n",
        "*   **inputs**: matrix of input points (numpy array of N data points x M features)\n",
        "\n",
        "Output:\n",
        "*   **features**: matrix of data points in the new feature space induced by the monomial basis functions (numpy array of N data points x M' features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxqB0NyK2DTU"
      },
      "source": [
        "def monomial_features(max_degree, inputs):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  features = np.zeros((inputs.shape[0],20))\n",
        "  return features"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYIbLxX7V2DW"
      },
      "source": [
        "# Function cross_validation_generalized_linear_regression\n",
        "\n",
        "This function performs k-fold cross validation to determine the best max degree of monomial basis functions in generalized linear regression\n",
        "\n",
        "Inputs:\n",
        "*   **k_folds**: # of folds in cross-validation (integer)\n",
        "*   **hyperparameters**: list of hyperparameters where each hyperparameter is a different max degree (list of integers)\n",
        "*   **inputs**: matrix of input points (numpy array of N data points by M' features)\n",
        "*   **targets**: vector of targets associated with the inputs (numpy array of N targets)\n",
        "\n",
        "Outputs:\n",
        "*   **best_hyperparam**: best max degree (integer)\n",
        "*   **best_mean_squared_error**: mean squared error achieved with best_hyperparam (float)\n",
        "*   **mean_squared_errors**: vector of mean squared errors for the corresponding hyperparameters (numpy array of floats)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZzoiZxLZMcV"
      },
      "source": [
        "def cross_validation_generalized_linear_regression(k_folds, hyperparameters, inputs, targets):\n",
        "\n",
        "  # dummy assignments until the function is filled in\n",
        "  best_hyperparam = 0\n",
        "  best_mean_squared_error = 0\n",
        "  mean_squared_errors = np.zeros(len(hyperparameters))\n",
        "  return best_hyperparam, best_mean_squared_error, mean_squared_errors"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ah5AAayZfVU"
      },
      "source": [
        "# Function: plot_generalized_linear_regression_mean_squared_errors\n",
        "\n",
        "Function that plots the mean squared errors for different lambda values (hyperparameters) in linear regression based on cross validation\n",
        "\n",
        "Inputs:\n",
        "*   **mean_squared_errors**: vector of mean squared errors for the corresponding hyperparameters (numpy array of floats)\n",
        "*   **hyperparams**: list of hyperparameters where each hyperparameter is a different degree (list of floats)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh9qZuzMatsZ"
      },
      "source": [
        "def plot_generalized_linear_regression_mean_squared_errors(mean_squared_errors,hyperparams):\n",
        "  plt.plot(hyperparams,mean_squared_errors)\n",
        "  plt.ylabel('mean squared error')\n",
        "  plt.xlabel('degree')\n",
        "  plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s21LRP5Qb3m8"
      },
      "source": [
        "# Main Generalized Linear Regression code\n",
        "\n",
        "Load data.\n",
        "Use k-fold cross validation to find the best max degree of the monomial basis functions.\n",
        "Plot mean squared errors for different degrees.\n",
        "Test generalized linear regression with the best degree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njlK2bf7sycQ"
      },
      "source": [
        "# load data\n",
        "train_inputs, train_targets, test_inputs, test_targets = load_generalized_linear_regression_data()\n",
        "\n",
        "# hyperparams (degrees) to be evaluated by cross validation\n",
        "hyperparams = range(1,21)\n",
        "k_folds = 10\n",
        "best_degree, best_mean_squared_error, mean_squared_errors = \\\n",
        "  cross_validation_generalized_linear_regression(k_folds,hyperparams,train_inputs,train_targets)\n",
        "\n",
        "# plot results\n",
        "plot_generalized_linear_regression_mean_squared_errors(mean_squared_errors,hyperparams)\n",
        "print('best degree: ' + str (best_degree))\n",
        "print('best cross validation mean squared error: ' + str(best_mean_squared_error))\n",
        "\n",
        "# train and evaluate with best degree\n",
        "lambda_value = 1\n",
        "generalized_train_inputs = monomial_features(best_degree, train_inputs)\n",
        "generalized_test_inputs = monomial_features(best_degree, test_inputs)\n",
        "weights = train_generalized_linear_regression(generalized_train_inputs,train_targets,lambda_value)\n",
        "mean_squared_error = eval_generalized_linear_regression(generalized_test_inputs, weights, test_targets)\n",
        "print('test mean squared error: ' + str(mean_squared_error))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}