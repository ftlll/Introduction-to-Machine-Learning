{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs480_fall20_asst3_gaussian_process_skeleton.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFXZug066bJX"
      },
      "source": [
        "# Upload files in Google Colab\n",
        "If you are running this Jupyter Notebook on Google Colab, run this cell to upload the data files (train_inputs.csv, train_targets.csv, test_inputs.csv, test_targets.csv) in the colab virtual machine.  You will be prompted to select files that you would like to upload. \n",
        "\n",
        "If you are running this Jupyter Notebook on your computer, you do not need to run this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqBJV_Br4XeI"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZDpxE4jmFwA"
      },
      "source": [
        "# Import libraries \n",
        "Do not use any other Python library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_1d0BPfmacB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6keYhcgi7nbf"
      },
      "source": [
        "# Function: load_gaussian_process_data\n",
        "\n",
        "This function loads the data for Gaussian Process Regression from a local drive into RAM\n",
        "\n",
        "Outputs:\n",
        "\n",
        "*   **train_inputs**: numpy array of N training data points x M features\n",
        "*   **train_targets**: numpy array of N training targets\n",
        "*   **test_inputs**: numpy array of N' test data points x M features\n",
        "*   **test_targets**: numpy array of N' test targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcG5U2lR7utt"
      },
      "source": [
        "def load_gaussian_process_data():\n",
        "  test_inputs = np.genfromtxt('test_inputs.csv', delimiter=',')\n",
        "  test_targets = np.genfromtxt('test_targets.csv', delimiter=',')\n",
        "  train_inputs = np.genfromtxt('train_inputs.csv', delimiter=',')\n",
        "  train_targets = np.genfromtxt('train_targets.csv', delimiter=',')\n",
        "  return train_inputs, train_targets, test_inputs, test_targets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwLo3p4f8bTa"
      },
      "source": [
        "# Function: predict_gaussian_process\n",
        "\n",
        "This function computes the mean and variance of the Gaussian posterior distribution over the outputs given some inputs.\n",
        "\n",
        "Inputs:\n",
        "*   **inputs**: matrix of input data points for which we want to make a prediction (numpy array of N data points x M features)\n",
        "*   **posterior**: function that computes Gaussian posterior distributions over the outputs given some inputs\n",
        "\n",
        "Output:\n",
        "*   **mean**: vector of mean values (numpy array of N floats)\n",
        "*   **variance**: vector of variance values (numpy array of N floats)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX04_wClRqkV"
      },
      "source": [
        "def predict_gaussian_process(inputs, posterior):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  mean = np.zeros(inputs.shape[0])\n",
        "  variance = np.zeros(inputs.shape[0])\n",
        "  return mean, variance"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmfPN7K0RtQ5"
      },
      "source": [
        "# Function eval_gaussian_process\n",
        "\n",
        "This function evaluates a set of predictions by computing the mean squared error with respect to the targets.  More precisely, compute the mean squared error between the means of the Gaussian posteriors and the targets. \n",
        "\n",
        "Inputs:\n",
        "*   **inputs**: matrix of input data points for which we will evaluate the predictions (numpy array of N data points x M features)\n",
        "*   **posterior**: function that computes Gaussian posterior distributions over the outputs given some inputs (function)\n",
        "*   **targets**: vector of targets associated with the inputs (numpy array of N targets)\n",
        "\n",
        "Output:\n",
        "*   **mean_squared_error**: mean squared error between the predicted Gaussian means and the targets (scalar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC14LEsvTxbu"
      },
      "source": [
        "def eval_gaussian_process(inputs, posterior, targets):\n",
        "  \n",
        "  # dummy assignment until the function is filled in\n",
        "  mean_squared_error = 0\n",
        "  return mean_squared_error"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMAzC5xXT0H-"
      },
      "source": [
        "# Function train_gaussian_process\n",
        "\n",
        "This function trains a Gaussian process.  More precisely, compute the inverse regularized gram matrix $(K+ \\sigma^2 I)^{-1}$ and then define a function that computes a posterior based on this inverse regularized gram matrix.\n",
        "\n",
        "Inputs:\n",
        "*   **train_inputs**: matrix of input training points (numpy array of N data points x M features)\n",
        "*   **train_targets**: vector of targets associated with the inputs (numpy array of N targets)\n",
        "*   **measurement_variance**: Variance $\\sigma^2$ of the measurement noise in the likelihood distribution $P({\\bf y}|{\\bf X},f) = N(f({\\bf X}),\\sigma^2{\\bf I})$ (scalar)\n",
        "*   **kernel**: function that computes the kernel between two sets of inputs (function)\n",
        "*   **kernel_param**: parameter for the kernel (scalar)\n",
        "\n",
        "Output:\n",
        "*   **posterior**: function that computes Gaussian posterior distributions over the outputs given some inputs (function)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DkzoT5QVy41"
      },
      "source": [
        "def train_gaussian_process(train_inputs, train_targets, measurement_variance, kernel, kernel_param):\n",
        "\n",
        "  # dummy assignment until this function is filled in\n",
        "  inverse_regularized_gram_matrix = np.zeros((train_inputs.shape[0],train_inputs.shape[0]))\n",
        "\n",
        "  # define a function that computes a posterior distribution over the outputs given some inputs\n",
        "  # inputs: \n",
        "  #     inputs: matrix of input points for which we would like to predict a Gaussian over the outputs (numpy array of N' data points x M features)\n",
        "  #     train_inputs: matrix of train inputs that serve as evidence for the posterior (numpy array of N data points x M features)\n",
        "  #     train_targets: vector of train targets that serve as evidence for the posterior (numpy array of N targets)\n",
        "  #     inverse_regularized_gram_matrix: (K + sigma^2 I)^{-1}\n",
        "  # outputs:\n",
        "  #     mean: vector of Gaussian means for each prediction (numpy array of N' means)\n",
        "  #     variance: vector of Gaussian variances for each prediction (numpy array of N' variances)\n",
        "  def posterior(inputs, train_inputs=train_inputs, train_targets=train_targets, inverse_regularized_gram_matrix=inverse_regularized_gram_matrix, kernel=kernel):\n",
        "\n",
        "    # dummy assignment until the function is filled in\n",
        "    mean = np.zeros(inputs.shape[0])\n",
        "    variance = np.zeros(inputs.shape[0])\n",
        "    return mean, variance\n",
        "\n",
        "  return posterior"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8h6kxL3qRkq"
      },
      "source": [
        "# Function identity_kernel\n",
        "\n",
        "This function computes the identity kernel: $k(x,x') = x^T x'$. \n",
        "\n",
        "Inputs:\n",
        "*   **inputs1**: matrix of input points (numpy array of N data points x M features)\n",
        "*   **inputs2**: matrix of input points (numpy array of N' data points x M features)\n",
        "*   **dummy_param**: this argument is never used since the identity kernel does not have any parameter (default value: None)\n",
        "\n",
        "Outputs:\n",
        "*   **gram_matrix**: matrix of kernel values (numpy array of N x N' values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csr7VZB9qYyV"
      },
      "source": [
        "def identity_kernel(inputs1,inputs2,dummy_param=None):\n",
        "\n",
        "  # dummy assignment until this function is filled in\n",
        "  gram_matrix = np.zeros(inputs1.shape[0],inputs2.shape[0])\n",
        "  return gram_matrix"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8iSqek2sXBC"
      },
      "source": [
        "# Function polynomial_kernel\n",
        "\n",
        "This function computes the polynomial kernel: $k(x,x') = (x^T x' + 1)^d$. \n",
        "\n",
        "Inputs:\n",
        "*   **inputs1**: matrix of input points (numpy array of N data points x M features)\n",
        "*   **inputs2**: matrix of input points (numpy array of N' data points x M features)\n",
        "*   **degree**: exponent d in the kernel (integer)\n",
        "\n",
        "Outputs:\n",
        "*   **gram_matrix**: matrix of kernel values (numpy array of N x N' values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS-afUBysZLx"
      },
      "source": [
        "def polynomial_kernel(inputs1,inputs2,degree):\n",
        "\n",
        "  # dummy assignment until this function is filled in\n",
        "  gram_matrix = np.zeros(inputs1.shape[0],inputs2.shape[0])\n",
        "  return gram_matrix"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImifaV1CtxZR"
      },
      "source": [
        "# Function gaussian_kernel\n",
        "\n",
        "This function computes the Gaussian kernel: $k(x,x') = e^{-\\frac{||x- x'||_2^2}{2w^2}}$. \n",
        "\n",
        "Inputs:\n",
        "*   **inputs1**: matrix of input points (numpy array of N data points x M features)\n",
        "*   **inputs2**: matrix of input points (numpy array of N' data points x M features)\n",
        "*   **width**: width w of the Gaussian kernel (scalar)\n",
        "\n",
        "Outputs:\n",
        "*   **gram_matrix**: matrix of kernel values (numpy array of N x N' values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7PadFLLt-hC"
      },
      "source": [
        "def gaussian_kernel(inputs1,inputs2,width):\n",
        "\n",
        "  # dummy assignment until this function is filled in\n",
        "  gram_matrix = np.zeros(inputs1.shape[0],inputs2.shape[0])\n",
        "  return gram_matrix"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYIbLxX7V2DW"
      },
      "source": [
        "# Function cross_validation_gaussian_process\n",
        "\n",
        "This function performs k-fold cross validation to determine the best kernel parameter in Gaussian process regression\n",
        "\n",
        "Inputs:\n",
        "*   **k_folds**: # of folds in cross-validation (integer)\n",
        "*   **kernel**: function that computes a kernel (function)\n",
        "*   **hyperparameters**: list of parameters for the kernel (list of scalars)\n",
        "*   **inputs**: matrix of input points (numpy array of N data points by M features)\n",
        "*   **targets**: vector of targets associated with the inputs (numpy array of N targets)\n",
        "*   **measurement_variance**: Variance $\\sigma^2$ of the measurement noise in the likelihood distribution $P({\\bf y}|{\\bf X},f) = N(f({\\bf X}),\\sigma^2{\\bf I})$ (scalar)\n",
        "\n",
        "Outputs:\n",
        "*   **best_hyperparam**: best parameter for the kernel (scalar)\n",
        "*   **best_mean_squared_error**: mean squared error achieved with best_hyperparam (float)\n",
        "*   **mean_squared_errors**: vector of mean squared errors for the corresponding hyperparameters (numpy array of floats)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZzoiZxLZMcV"
      },
      "source": [
        "def cross_validation_gaussian_process(k_folds, kernel, hyperparameters, inputs, targets, measurement_variance):\n",
        "\n",
        "  # dummy assignments until the function is filled in\n",
        "  best_hyperparam = 0\n",
        "  best_mean_squared_error = 0\n",
        "  mean_squared_errors = np.zeros(len(hyperparameters))\n",
        "  return best_hyperparam, best_mean_squared_error, mean_squared_errors"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ah5AAayZfVU"
      },
      "source": [
        "# Function: plot_gaussian_process_mean_squared_errors\n",
        "\n",
        "Function that plots the mean squared errors for different hyperparameters in Gaussian process regression based on cross validation\n",
        "\n",
        "Inputs:\n",
        "*   **mean_squared_errors**: vector of mean squared errors for the corresponding hyperparameters (numpy array of floats)\n",
        "*   **hyperparams**: list of hyperparameters where each hyperparameter is a different lambda value (list of floats)\n",
        "*   **xlabel**: string to label the x-axis (string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh9qZuzMatsZ"
      },
      "source": [
        "def plot_gaussian_process_mean_squared_errors(mean_squared_errors,hyperparams,xlabel):\n",
        "  plt.plot(hyperparams,mean_squared_errors)\n",
        "  plt.ylabel('mean squared error')\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s21LRP5Qb3m8"
      },
      "source": [
        "# Main Gaussian Process code\n",
        "\n",
        "Load data.  Then evaluate the identity kernel, polynomial kernel and Gaussian kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njlK2bf7sycQ"
      },
      "source": [
        "# load data\n",
        "train_inputs, train_targets, test_inputs, test_targets = load_gaussian_process_data()\n",
        "\n",
        "# likelihood parameter (see definition of train_gaussian_process for more details)\n",
        "measurement_variance = 1\n",
        "\n",
        "# number of folds in k-fold cross validation\n",
        "k_folds = 10\n",
        "\n",
        "# identity kernel\n",
        "print('\\nIdentity Kernel')\n",
        "posterior = train_gaussian_process(train_inputs, train_targets, measurement_variance, identity_kernel, None)\n",
        "mean_squared_error = eval_gaussian_process(test_inputs, posterior, test_targets)\n",
        "print('test mean squared error with identity kernel: ' + str(mean_squared_error))\n",
        "\n",
        "# polynomial kernel\n",
        "print('\\nPolynomial Kernel')\n",
        "# degrees to be evaluated by cross validation\n",
        "hyperparams = range(1,21)\n",
        "best_degree, best_mean_squared_error, mean_squared_errors = \\\n",
        "  cross_validation_gaussian_process(k_folds,polynomial_kernel,hyperparams,train_inputs,train_targets,measurement_variance)\n",
        "plot_gaussian_process_mean_squared_errors(mean_squared_errors,hyperparams,'degree')\n",
        "print('best degree: ' + str (best_degree))\n",
        "print('best cross validation mean squared error: ' + str(best_mean_squared_error))\n",
        "posterior = train_gaussian_process(train_inputs, train_targets, measurement_variance, polynomial_kernel, best_degree)\n",
        "mean_squared_error = eval_gaussian_process(test_inputs, posterior, test_targets)\n",
        "print('test mean squared error with polynomial kernel: ' + str(mean_squared_error))\n",
        "\n",
        "# gaussian kernel\n",
        "print('\\nGaussian Kernel')\n",
        "# gaussian widths to be evaluated by cross validation\n",
        "hyperparams = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "best_width, best_mean_squared_error, mean_squared_errors = \\\n",
        "  cross_validation_gaussian_process(k_folds,gaussian_kernel,hyperparams,train_inputs,train_targets,measurement_variance)\n",
        "plot_gaussian_process_mean_squared_errors(mean_squared_errors,hyperparams,'width')\n",
        "print('best width: ' + str (best_width))\n",
        "print('best cross validation mean squared error: ' + str(best_mean_squared_error))\n",
        "posterior = train_gaussian_process(train_inputs, train_targets, measurement_variance, gaussian_kernel, best_width)\n",
        "mean_squared_error = eval_gaussian_process(test_inputs, posterior, test_targets)\n",
        "print('test mean squared error with Gaussian kernel: ' + str(mean_squared_error))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}